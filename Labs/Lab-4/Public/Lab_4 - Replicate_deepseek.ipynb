{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d240756",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4097bac9",
   "metadata": {},
   "source": [
    "# üî¨ Virtual Lab 4: Running Llama Models and Deepseek on Replicate  \n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; padding: 15px; border-radius: 10px; background-color: #f4f4f4;\">\n",
    "\n",
    "### üöÄ **Platform**  \n",
    "**Replicate**  \n",
    "\n",
    "### üè∑Ô∏è **Models Used**  \n",
    "- **meta/meta-llama-3-70b-instruct**  \n",
    "- **meta-llama-3.1-405b-instruct**  \n",
    "- **meta/meta-llama-3-8b-instruct**  \n",
    "- **deepseek-ai/deepseek-r1**  \n",
    "\n",
    "### üõ†Ô∏è **Frameworks Used**  \n",
    "- **LlamaIndex**  \n",
    "- **LangChain / LangGraph**  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17fd9c-9332-4ad3-805d-49c3fbb317fd",
   "metadata": {},
   "source": [
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2b904f-721f-49b8-9423-a14cd7e925d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.12.22)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.22 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.12.22)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.6.8)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.3.25)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.4.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.22->llama-index) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.22->llama-index) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.13)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
      "Requirement already satisfied: pandas in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.2)\n",
      "Requirement already satisfied: click in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.22->llama-index) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.22->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.22->llama-index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud-services>=0.6.2->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.22->llama-index) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.5.2)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-llms-ollama) (0.12.22)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-llms-ollama) (0.4.7)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.18.3)\n",
      "Requirement already satisfied: anyio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.14.0)\n",
      "Requirement already satisfied: click in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (24.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: llama-index-llms-replicate in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-llms-replicate) (0.12.22)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2025.2.0)\n",
      "Requirement already satisfied: httpx in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.18.3)\n",
      "Requirement already satisfied: click in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (3.26.1)\n",
      "Requirement already satisfied: anyio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (24.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-replicate) (1.3.1)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.29.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-embeddings-huggingface) (0.12.22)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-embeddings-huggingface) (3.4.1)\n",
      "Requirement already satisfied: filelock in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.13)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.38)\n",
      "Requirement already satisfied: dataclasses-json in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.15.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.18.3)\n",
      "Requirement already satisfied: click in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: anyio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Requirement already satisfied: llama-parse in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.6.2)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-parse) (0.6.3)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud-services>=0.6.2->llama-parse) (8.1.8)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.11 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud-services>=0.6.2->llama-parse) (0.1.13)\n",
      "Requirement already satisfied: llama-index-core>=0.11.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud-services>=0.6.2->llama-parse) (0.12.22)\n",
      "Requirement already satisfied: pydantic!=2.10 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud-services>=0.6.2->llama-parse) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud-services>=0.6.2->llama-parse) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.2->llama-parse) (2025.1.31)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.2->llama-parse) (0.28.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (2025.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (11.1.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.17.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic!=2.10->llama-cloud-services>=0.6.2->llama-parse) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic!=2.10->llama-cloud-services>=0.6.2->llama-parse) (2.27.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.18.3)\n",
      "Requirement already satisfied: anyio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.2->llama-parse) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.2->llama-parse) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.2->llama-parse) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.2->llama-parse) (0.14.0)\n",
      "Requirement already satisfied: joblib in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.2->llama-parse) (24.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.2->llama-parse) (1.3.1)\n",
      "Requirement already satisfied: replicate in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (1.0.4)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from replicate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from replicate) (24.2)\n",
      "Requirement already satisfied: pydantic>1.10.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from replicate) (2.10.6)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from replicate) (4.12.2)\n",
      "Requirement already satisfied: anyio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic>1.10.7->replicate) (2.27.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-llms-ollama\n",
    "!pip install llama-index-llms-replicate\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-parse\n",
    "!pip install replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d450780-3093-4d03-8b6c-64cfcd87d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a9545-3a73-499e-894f-e3d6ac0db46c",
   "metadata": {},
   "source": [
    "### Setup LLM using Replicate\n",
    "\n",
    "Make sure you have REPLICATE_API_TOKEN specified!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a4608f-0b1f-4548-9bd7-c8f80d75a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"REPLICATE_API_TOKEN\"] = \"<YOUR_API_KEY>\"\n",
    "\n",
    "import os\n",
    "import replicate\n",
    "from Constants import Constants\n",
    "# Set the REPLICATE_API_TOKEN environment variable\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = Constants.REPLICATE_API_KEY\n",
    "import os\n",
    "import replicate\n",
    "\n",
    "# Set the REPLICATE_API_TOKEN environment variable\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = Constants.REPLICATE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60597af6-dd74-455e-930d-fd8929c7054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.replicate import Replicate\n",
    "\n",
    "llm_replicate = Replicate(model=\"deepseek-ai/deepseek-r1\", api_token=os.environ[\"REPLICATE_API_TOKEN\"])\n",
    "# llm_replicate = Replicate(model=\"meta/meta-llama-3-70b-instruct\", api_token=os.environ[\"REPLICATE_API_TOKEN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9c3b7-dd54-4522-9b51-1ed3de87d41b",
   "metadata": {},
   "source": [
    "### Setup Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4bbe98-f1e7-4d94-82e1-503673026bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74842474-df89-462e-89e6-0b65466f4cfe",
   "metadata": {},
   "source": [
    "### Define Global Settings Configuration\n",
    "\n",
    "In LlamaIndex, you can define global settings so you don't have to pass the LLM / embedding model objects everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e587d04-312f-41ce-a224-d27c1d1287df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm_replicate\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d814780-54f7-49d3-a062-a8edca56fe8b",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "\n",
    "Here you'll download data that's used in section 2 and onwards.\n",
    "\n",
    "We'll download some articles on Kendrick, Drake, and their beef (as of May 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bac834b-2caf-42dd-89da-0b96585d5c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    17  100    17    0     0     33      0 --:--:-- --:--:-- --:--:--    33\n",
      "100   475    0   475    0     0    466      0 --:--:--  0:00:01 --:--:--     0\n",
      "100 47.0M  100 47.0M    0     0  17.7M      0  0:00:02  0:00:02 --:--:-- 45.0M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    17  100    17    0     0     44      0 --:--:-- --:--:-- --:--:--    44\n",
      "100   475    0   475    0     0    595      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 4483k  100 4483k    0     0  3602k      0  0:00:01  0:00:01 --:--:-- 3602k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    17  100    17    0     0     34      0 --:--:-- --:--:-- --:--:--    34\n",
      "100   475    0   475    0     0    430      0 --:--:--  0:00:01 --:--:--   430\n",
      "100 5464k  100 5464k    0     0  3278k      0  0:00:01  0:00:01 --:--:-- 21.1M\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!curl -L \"https://www.dropbox.com/scl/fi/t1soxfjdp0v44an6sdymd/drake_kendrick_beef.pdf?rlkey=u9546ymb7fj8lk2v64r6p5r5k&st=wjzzrgil&dl=1\" -o data/drake_kendrick_beef.pdf\n",
    "!curl -L \"https://www.dropbox.com/scl/fi/nts3n64s6kymner2jppd6/drake.pdf?rlkey=hksirpqwzlzqoejn55zemk6ld&st=mohyfyh4&dl=1\" -o data/drake.pdf\n",
    "!curl -L \"https://www.dropbox.com/scl/fi/8ax2vnoebhmy44bes2n1d/kendrick.pdf?rlkey=fhxvn94t5amdqcv9vshifd3hj&st=dxdtytn6&dl=1\" -o data/kendrick.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69626d36-99ec-4a37-8d01-ced79aa9fd53",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "We load data using LlamaParse by default, but you can also choose to opt for our free pypdf reader (in SimpleDirectoryReader by default) if you don't have an account! \n",
    "\n",
    "1. LlamaParse: Signup for an account here: cloud.llamaindex.ai. You get 1k free pages a day, and paid plan is 7k free pages + 0.3c per additional page. LlamaParse is a good option if you want to parse complex documents, like PDFs with charts, tables, and more. \n",
    "\n",
    "2. Default PDF Parser (In `SimpleDirectoryReader`). If you don't want to signup for an account / use a PDF service, just use the default PyPDF reader bundled in our file loader. It's a good choice for getting started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e3e6a28-e902-4b6f-8c4d-250042ee71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "docs_kendrick = SimpleDirectoryReader(input_files=[\"data/kendrick.pdf\"]).load_data()\n",
    "docs_drake = SimpleDirectoryReader(input_files=[\"data/drake.pdf\"]).load_data()\n",
    "docs_both = SimpleDirectoryReader(input_files=[\"data/drake_kendrick_beef.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3916f569-4631-498e-90a5-ee185df7a119",
   "metadata": {},
   "source": [
    "## 1. Basic Completion and Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc49bb-ab64-4070-8711-e9a0a860db3c",
   "metadata": {},
   "source": [
    "### Call complete with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5328c44a-c17e-4bf6-bbe7-71de75afae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user is asking whether I like Drake or Kendrick Lamar better. First, I need to remember that as an AI, I don't have personal preferences. The answer should reflect that while also providing some context about the two artists. Let me think about their careers and musical styles.\n",
      "\n",
      "Drake is a Canadian rapper, singer, and songwriter. He's known for his versatility, blending rap with R&B, and he's had a lot of commercial success. His themes often revolve around relationships, fame, and personal struggles. Albums like \"Take Care\" and \"Scorpion\" are really popular. He's also known for catchy hooks and hits that top the charts.\n",
      "\n",
      "Kendrick Lamar, on the other hand, is from Compton and is highly regarded for his lyrical depth and storytelling. His works often tackle social issues, systemic racism, and personal growth. Albums like \"good kid, m.A.A.d city\" and \"To Pimp a Butterfly\" are critically acclaimed and considered masterpieces. Kendrick has a more conscious approach to hip-hop, with complex lyrics and concept albums.\n",
      "\n",
      "I should mention that Drake is more mainstream and has a broader appeal, while Kendrick is often praised for his artistry and impact on the culture. Both have different strengths and fan bases. Also, maybe touch on their influence in the music industry and how they contribute to hip-hop in different ways.\n",
      "\n",
      "Need to make sure I don't show bias, so present facts and let the user decide based on their own preferences. Maybe include that it's subjective and depends on what aspects of music the listener values more. Should also check if there are any notable collaborations or controversies between them, but I don't think that's necessary here unless relevant. Keep the response informative but neutral.\n",
      "</think>\n",
      "\n",
      "As an AI, I don‚Äôt have personal preferences, but I can share insights about both artists to help you decide!  \n",
      "\n",
      "**Drake** is celebrated for his melodic versatility, chart-topping hits, and ability to blend rap with R&B. His music often explores themes of fame, relationships, and personal reflection, resonating with a massive global audience. Artists like him dominate mainstream culture and evolve with trends, making his work broadly accessible.  \n",
      "\n",
      "**Kendrick Lamar** is widely regarded as a lyrical genius and storyteller, tackling complex themes like systemic injustice, identity, and spirituality. Albums like *To Pimp a Butterfly* and *DAMN.* are praised for their conceptual depth and social commentary, earning him critical acclaim and a dedicated fanbase that values artistry over commercial appeal.  \n",
      "\n",
      "Your preference might depend on what you prioritize:  \n",
      "- **Drake** for catchy, relatable, and versatile vibes.  \n",
      "- **Kendrick** for introspective, politically charged, and meticulously crafted narratives.  \n",
      "\n",
      "Both have shaped modern hip-hop in distinct ways‚Äîneither is \"better,\" just different! Who do *you* lean toward? üòä\n"
     ]
    }
   ],
   "source": [
    "response = llm_replicate.complete(\"do you like drake or kendrick better?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76e4a12c-169a-4ed2-88e3-9b0d2ec12111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to explain why someone likes Drake more than Kendrick Lamar. Let me start by recalling what I know about both artists. Drake is a Canadian rapper, singer, and songwriter known for his melodic style and emotional lyrics. He's been really popular for over a decade, with hits in both hip-hop and pop. Kendrick Lamar is also a highly respected rapper, known for his deep lyrics, storytelling, and social commentary. He's often praised for his artistry and impactful albums.\n",
      "\n",
      "The user wants reasons why someone might prefer Drake over Kendrick. Let me think about the possible differences in their music styles, public personas, themes, and other factors. Let's start with musical style. Drake tends to blend singing and rapping, which makes his music more accessible and versatile. He's known for catchy hooks and melodies, which might appeal to a broader audience. His music often deals with personal emotions, relationships, and fame. \n",
      "\n",
      "Kendrick, on the other hand, focuses more on complex lyricism, narratives, and addressing social issues. His albums like \"Good Kid, M.A.A.D City\" and \"To Pimp a Butterfly\" are concept albums with intricate storytelling. While critically acclaimed, they might not be as immediately catchy or mainstream as Drake's work. \n",
      "\n",
      "Another point is the consistency and volume of output. Drake releases music frequently and stays relevant in the charts. He's mastered the art of creating hits that dominate radio and streaming platforms. Kendrick takes more time between projects, which can be seen as a mark of quality, but for fans who want more frequent content, Drake might be preferable.\n",
      "\n",
      "Drake's versatility across genres could be another factor. He collaborates with artists from different genres, incorporating R&B, dancehall, and pop into his music. This variety might attract listeners who enjoy different styles. Kendrick's work is more rooted in traditional hip-hop, jazz, and funk influences, which is great but maybe not as varied.\n",
      "\n",
      "Personal connection might play a role. Drake's themes about heartbreak, success, and personal struggles might resonate more on an individual level for some listeners. His lyrics are introspective but in a more relatable, everyday way. Kendrick's themes are more about systemic issues, identity, and community, which are powerful but might not feel as personal to some.\n",
      "\n",
      "Public persona and media presence could also influence preference. Drake is very active in the media, engages with fans on social platforms, and has a more approachable, charismatic image. Kendrick is more private and selective with public appearances, which can make him seem more enigmatic but less accessible.\n",
      "\n",
      "Live performances might differ too. Drake's concerts are known for high energy and spectacle, while Kendrick's might focus more on the artistic presentation and message. Some fans might prefer the entertainment factor of Drake's shows.\n",
      "\n",
      "It's important to note that this is subjective. Both artists have their strengths, and preferring one over the other doesn't diminish the other's talent. But the user wants reasons to prefer Drake, so I need to highlight these points without bashing Kendrick.\n",
      "\n",
      "I should structure the answer by listing each reason clearly, explaining why each aspect makes Drake more appealing to some. Make sure to mention that it's a matter of personal taste and acknowledge Kendrick's strengths as well to keep it balanced.\n",
      "</think>\n",
      "\n",
      "As a Drake fan, my preference for his music over Kendrick Lamar‚Äôs stems from a few key factors, all rooted in personal taste and what I value most in music. Here‚Äôs a breakdown:\n",
      "\n",
      "1. **Versatility and Genre-Blending**:  \n",
      "   Drake effortlessly bridges hip-hop, R&B, pop, and even dancehall, creating songs that fit any mood. Whether it‚Äôs a club banger like ‚ÄúGod‚Äôs Plan,‚Äù a reflective track like ‚ÄúMarvins Room,‚Äù or a smooth R&B groove like ‚ÄúPassionfruit,‚Äù his range keeps his discography fresh. Kendrick, while a lyrical genius, often stays anchored in dense, concept-driven hip-hop, which can feel less accessible for casual listening.\n",
      "\n",
      "2. **Relatability and Emotional Vulnerability**:  \n",
      "   Drake‚Äôs lyrics often explore personal struggles, relationships, and the complexities of fame in a way that feels intimate. Tracks like ‚ÄúHold On, We‚Äôre Going Home‚Äù or ‚ÄúNice For What‚Äù blend introspection with catchy melodies, making emotions feel universal. Kendrick‚Äôs work, while profound, prioritizes societal commentary (e.g., *To Pimp a Butterfly*) over individual vulnerability, which might resonate less for someone seeking personal connection.\n",
      "\n",
      "3. **Consistency and Cultural Dominance**:  \n",
      "   Drake‚Äôs ability to stay *everywhere*‚Äîconstantly dropping hits, memes, and trends‚Äîmakes him feel like a soundtrack to daily life. His prolific output (e.g., annual albums, surprise drops) ensures there‚Äôs always something new. Kendrick‚Äôs deliberate, slower release cycle reflects artistic integrity, but for fans craving frequent, evolving content, Drake‚Äôs consistency is unmatched.\n",
      "\n",
      "4. **Catchy Melodies and Singing-Rapping Hybrid**:  \n",
      "   Drake‚Äôs melodic flow and earworm hooks make his music instantly gratifying. His seamless transition between rapping and singing (e.g., ‚ÄúOne Dance,‚Äù ‚ÄúHotline Bling‚Äù) gives his work broad appeal. Kendrick‚Äôs focus on intricate bars and dense storytelling, while brilliant, can demand more active engagement, which isn‚Äôt always what listeners want.\n",
      "\n",
      "5. **Cultural Persona and Accessibility**:  \n",
      "   Drake‚Äôs charismatic, meme-friendly persona (e.g., ‚ÄúToronto mans‚Äù vibes, dad jokes, sports fandom) makes him feel like a relatable friend. He engages fans through social media, interviews, and playful feuds. Kendrick, meanwhile, maintains a more enigmatic, reserved image, which adds to his mystique but can create distance.\n",
      "\n",
      "6. **Live Experience**:  \n",
      "   Drake‚Äôs concerts are high-energy spectacles with flashy production, crowd interaction, and hit-after-hit setlists. Kendrick‚Äôs shows lean into theatrical storytelling, which is powerful but may not match the sheer ‚Äúvibe‚Äù of a Drake performance for some fans.\n",
      "\n",
      "**Important Note**: This isn‚Äôt about diminishing Kendrick, whose artistry and impact on hip-hop are undeniable. It‚Äôs about preference‚ÄîDrake‚Äôs strengths align with what I seek in music: versatility, emotional immediacy, and a soundtrack for both parties and introspection. Kendrick fans might prioritize lyrical depth and social themes, and that‚Äôs the beauty of music‚Äîit‚Äôs subjective! ü¶â vs. üêê, both winning."
     ]
    }
   ],
   "source": [
    "stream_response = llm_replicate.stream_complete(\n",
    "    \"you're a drake fan. tell me why you like drake more than kendrick\"\n",
    ")\n",
    "\n",
    "for t in stream_response:\n",
    "    print(t.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1a61b-f95a-472e-90f1-df9cfe76bd39",
   "metadata": {},
   "source": [
    "### Call chat with a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbce5aea-f343-445c-981c-30a6d8142251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"You are Kendrick.\"),\n",
    "    ChatMessage(role=\"user\", content=\"Write a verse.\"),\n",
    "]\n",
    "response = llm_replicate.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51a860ee-26d0-4e31-ade5-ba4b71ad45cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: <think>\n",
      "Alright, let's get into the mindset of Kendrick Lamar. First, I need to think about his style: introspective, socially conscious, clever wordplay, and complex rhyme schemes. His verses often tackle themes like systemic racism, personal struggles, identity, and his roots in Compton.\n",
      "\n",
      "Start with a strong opening line that grabs attention. Maybe use a metaphor related to fame or struggle. Kendrick often uses alliteration and internal rhymes, so I should incorporate that. Need to maintain a rhythmic flow, possibly using a AABB or ABAB rhyme scheme. Let's think about current events or personal challenges he might address. Maybe touch on authenticity in the music industry, social justice, or personal growth. Avoid clich√©s, keep it gritty and real. Use specific imagery related to Compton, like streetlights, corner stores, or cultural references. Also, consider the beat ‚Äì the verse should have a cadence that fits a typical Kendrick track, with pauses and emphasis on certain syllables. Don't forget the punchlines and double entendres. Maybe end with a thought-provoking line that leaves an impact. Let me piece it together, line by line, ensuring each part connects and builds on the previous one. Check for consistency in theme and flow. Alright, let's draft it.\n",
      "</think>\n",
      "\n",
      "**[Verse]**  \n",
      "Crown heavy, the weight of the sins in my city's confession,  \n",
      "Bloodstains on the dollar, they profit off the oppressed existence.  \n",
      "I juggle the chaos, the fame like a chalice of acid,  \n",
      "Truth serum drippin' when I scribble, these lines‚Äîa catharsis.  \n",
      "\n",
      "Compton crossfires, where the wolves don‚Äôt shepherd the lambs,  \n",
      "Google Maps can‚Äôt map the pain where the crack babies stand.  \n",
      "They said, \"Pray for the rain,\" but the drought‚Äôs in the plan,  \n",
      "Politricks in the air, got me coughin‚Äô up metaphors and SAMs.  \n",
      "\n",
      "I‚Äôm the ghost of Tupac, wrapped in Obama's old suit,  \n",
      "Dodgin‚Äô the pitfalls of kings‚Äîwatch how the paranoia execute.  \n",
      "Every line a landmine, I walk tightropes in size twos,  \n",
      "Speak in codes, but the message? \"Y‚Äôall better shoot truer.\"  \n",
      "\n",
      "The industry‚Äôs a rented casket, plaques hang like epitaphs,  \n",
      "Streamin' numbers rise while the youth tally body taps.  \n",
      "But I‚Äômma stay tectonic, shift plates ‚Äôtil the fault cracks,  \n",
      "Witness Kendrick‚Äîthe diamond formed where the asphalt black‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0368e7e1-af0d-4f6b-94e5-bb2cdcab022c",
   "metadata": {},
   "source": [
    "## 2. Basic RAG (Vector Search, Summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88b129-df70-4133-81bc-8840681e7aba",
   "metadata": {},
   "source": [
    "### Basic RAG (Vector Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11eeb942-a154-46dc-b007-8943db32abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs_both)\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39843765-2670-43aa-95c5-8093e59d5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Tell me about family matters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce6c59d4-37c9-4784-a373-2f6f8d872737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out what \"Family Matters\" refers to based on the provided context. Let me go through the information given.\n",
      "\n",
      "From page 21, it's mentioned that Drake released a diss track called \"Family Matters\" which is three songs in one, on three different beats. The track includes verses targeting Kendrick Lamar and others like Metro Boomin, Rick Ross, The Weeknd, and A$AP Rocky. However, the non-Kendrick parts are criticized as distracting and having some of Drake's laziest writing.\n",
      "\n",
      "Page 24 adds that in \"Family Matters,\" Drake accuses Kendrick of infidelity, neglecting his family by preferring bachelor life in New York, and domestic abuse against the mother of his children. Kendrick's response, \"Meet the Grahams,\" counters these allegations and even claims Drake has a hidden daughter. Kendrick also brings up serious accusations like Drake associating with sex offenders and facing potential legal issues similar to Harvey Weinstein.\n",
      "\n",
      "Page 29 talks about Drake's response in \"The Heart Part 6,\" where he defends himself against the pedophilia accusations, denies involvement with underage girls, and mocks Kendrick's tactics. Drake also references Kendrick's past music to counter the allegations.\n",
      "\n",
      "Putting this together, \"Family Matters\" is Drake's diss track aimed at Kendrick, making several personal and serious accusations. The response from Kendrick was even more intense, leading to a back-and-forth with Drake defending himself. The track's title likely plays on the double meaning of family issues and the TV show \"Family Matters.\"\n",
      "</think>\n",
      "\n",
      "**Answer:**  \n",
      "\"Family Matters\" is a diss track by Drake targeting Kendrick Lamar, released as part of their highly publicized feud. Here‚Äôs a breakdown based on the context provided:  \n",
      "\n",
      "1. **Structure and Content**:  \n",
      "   - The track is described as \"three songs in one,\" featuring three different beats. It includes a verse announcing its release and a seven-and-a-half-minute main diss track with an accompanying video.  \n",
      "   - Drake directs most of his bars at Kendrick but also addresses other rivals like Metro Boomin, Rick Ross, The Weeknd, and A$AP Rocky. Critics, however, found the non-Kendrick disses less cohesive and \"lazy.\"  \n",
      "\n",
      "2. **Accusations Against Kendrick**:  \n",
      "   - Drake accuses Kendrick of **domestic abuse** (alleging he physically harmed Whitney, his partner and mother of his children).  \n",
      "   - He claims Kendrick is neglectful of his family, prioritizing a bachelor lifestyle in New York over posting photos or spending time with them.  \n",
      "   - Drake also insinuates **paternity issues**, suggesting one of Kendrick‚Äôs children might be fathered by his friend and collaborator Dave Free.  \n",
      "\n",
      "3. **Kendrick‚Äôs Response**:  \n",
      "   - Kendrick retaliates with tracks like **\"Euphoria\"** and **\"Meet the Grahams\"**, escalating the conflict by alleging Drake has a **hidden 11-year-old daughter** and associating with sex offenders. He also hints at looming legal troubles for Drake comparable to Harvey Weinstein‚Äôs case.  \n",
      "\n",
      "4. **Drake‚Äôs Defense**:  \n",
      "   - In later tracks (e.g., **\"The Heart Part 6\"**), Drake denies pedophilia accusations, stating, ‚ÄúIf I was fucking young girls, I‚Äôd have been arrested.‚Äù He also mocks Kendrick‚Äôs tactics, claiming he fed Kendrick false intel to expose his eagerness to attack.  \n",
      "\n",
      "5. **Broader Feud Dynamics**:  \n",
      "   - The battle mirrors past rap beefs (e.g., Drake vs. Pusha T), with both artists leveraging deeply personal and controversial accusations, including family drama, infidelity, and legal threats.  \n",
      "\n",
      "**Key Takeaway**: \"Family Matters\" intensified the Drake-Kendrick feud, blending musical rivalry with incendiary personal allegations. Kendrick‚Äôs response outshone Drake‚Äôs initial salvo, pivoting the narrative toward darker, more serious claims that dominated public discourse.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c80b3a-064c-4f8a-85ea-488d501fdc21",
   "metadata": {},
   "source": [
    "### Basic RAG (Summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f706e6e8-8e31-491a-8a60-a0937d96b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "\n",
    "summary_index = SummaryIndex.from_documents(docs_both)\n",
    "summary_engine = summary_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69deb896-c39c-4c97-ba5b-cc0290033d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = summary_engine.query(\n",
    "    \"Given your assessment of this article, who won the beef?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e954f2bb-cab4-41d3-afa3-a56b3301a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's look at the new context provided. The user added multiple pages from a GQ article, but most of them seem to be irrelevant‚Äîlike sections about Shaboozey, A$AP Rocky, sponsored links, and other unrelated articles. The actual content related to the Kendrick vs. Drake beef is minimal here. Pages 30-34 of the PDF don't provide any new information about the beef; they're mostly other articles, ads, and the end of the original piece.\n",
      "\n",
      "The original analysis already integrated the key points from the initial article, including the escalation of allegations, Kendrick's strategic releases, and the public reception. Since the new context doesn't add any substantial details about the beef itself, there's no need to refine the answer further. The original refined answer remains accurate and comprehensive based on the information available.\n",
      "</think>\n",
      "\n",
      "The provided context (pages 30-34 of the GQ article) contains no substantive new information about the Kendrick Lamar/Drake beef‚Äîit primarily features unrelated content (e.g., articles about A$AP Rocky, Shaboozey, ads, newsletter prompts). Since no fresh insights or analysis about the feud are included here, **the original refined answer remains valid and unaltered**.  \n",
      "\n",
      "**Original Answer (Unchanged):**  \n",
      "**Kendrick Lamar** cements his victory through a relentless, multi-faceted assault that combines moral condemnation, tactical speed, and crowd-winning appeal. His rapid-fire diss tracks (*‚ÄúNot Like Us,‚Äù ‚ÄúMeet the Grahams‚Äù*) escalate to career-ending claims (tying Drake to sex offenders), while pivoting to anthemic West Coast production to dominate public sentiment. Drake‚Äôs reactive responses (*‚ÄúFamily Matters,‚Äù* Instagram clapbacks) fail to match Kendrick‚Äôs strategic execution, pace, or cultural resonance.  \n",
      "\n",
      "**Winner: Kendrick Lamar**‚Äîa masterclass in modern rap warfare.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3eb3e3-ecd5-47f0-9cc4-dbfa5583dd15",
   "metadata": {},
   "source": [
    "## 3. Advanced RAG (Routing, Sub-Questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af1098-4221-4482-b095-9e300218bc1e",
   "metadata": {},
   "source": [
    "### Build a Router that can choose whether to do vector search or summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0de5a8d-9ce7-4096-9b15-44c385dec177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "vector_tool = QueryEngineTool(\n",
    "    index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"vector_search\",\n",
    "        description=\"Useful for searching for specific facts.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "summary_tool = QueryEngineTool(\n",
    "    index.as_query_engine(response_mode=\"tree_summarize\"),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"summary\",\n",
    "        description=\"Useful for summarizing an entire document.\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fb77b7b-7795-4891-9e6a-a7e0740e0254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The question seeks specific facts about the song 'Meet the Grahams' and its significance, which aligns with Choice 1's focus on factual search rather than summarizing an entire document..\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "\n",
    "query_engine = RouterQueryEngine.from_defaults(\n",
    "    [vector_tool, summary_tool], select_multi=False, verbose=True\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"Tell me about the song meet the grahams - why is it significant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8988d821-f27b-4661-8e65-521d55f83857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to answer the question about why \"Meet the Grahams\" is significant based on the provided context. Let me look through the given pages.\n",
      "\n",
      "On page 27, it says Drake laughed off \"Meet the Grahams\" as a sign that team PG is desperate and \"in shambles.\" The song is mentioned in the same paragraph as \"Not Like Us,\" where Kendrick is proving he's more war-ready. But the main details about \"Meet the Grahams\" are on page 26. \n",
      "\n",
      "Page 26 describes \"Meet the Grahams\" as an uncomfortable listen, contrasting it with Drake's track \"Family Matters,\" which alleges Kendrick \"beats his queen.\" The author compares it to Pusha T's diss track but notes that \"Meet the Grahams\" is \"joyless,\" suggesting it's more harsh or serious. Kendrick was in danger of losing the audience by taking things too far, but then released \"Not Like Us\" to lighten the mood. \n",
      "\n",
      "Significance points: It's part of the Kendrick/Drake beef, aggressive disses, puts pressure on Drake, but risked alienating listeners for being too intense. Also, it's contrasted with the more upbeat \"Not Like Us.\" The song's content includes serious allegations, making it a significant escalation in their feud.\n",
      "</think>\n",
      "\n",
      "**Answer:**  \n",
      "\"Meet the Grahams\" is a diss track by Kendrick Lamar targeting Drake, notable for its aggressive escalation in their feud. It is significant for several reasons:  \n",
      "\n",
      "1. **Uncomfortable Intensity**: The song is described as a \"joyless,\" direct attack, contrasting with the more playful or rhythmic disses typical in rap beefs. Kendrick accuses Drake of serious personal and moral failings (e.g., alleging Drake associates with \"bad dudes\" and is a \"sex pest\").  \n",
      "\n",
      "2. **Strategic Pressure**: It applied back-to-back pressure on Drake after Kendrick‚Äôs earlier track \"Euphoria,\" suffocating Drake‚Äôs ability to respond effectively and shifting momentum in Kendrick‚Äôs favor.  \n",
      "\n",
      "3. **Audience Reception Risks**: While impactful, the track risked alienating listeners due to its unrelentingly harsh tone. Critics likened it to \"that kid at the lunch table who takes things too far,\" prompting Kendrick to pivot with the lighter, party-friendly \"Not Like Us\" to regain broader appeal.  \n",
      "\n",
      "4. **Cultural Context**: The song intensified the narrative of Kendrick representing a collective disdain for Drake‚Äôs alleged inauthenticity (\"a larger 'we'\"), framing the feud as a broader cultural clash rather than a personal spat.  \n",
      "\n",
      "Drake dismissed the track as a sign of desperation from Kendrick‚Äôs camp, but its severity and timing cemented its role as a pivotal moment in the beef, showcasing Kendrick‚Äôs willingness to push boundaries lyrically and strategically.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec76d3-bab0-4427-b50b-c846c17a272f",
   "metadata": {},
   "source": [
    "### Break Complex Questions down into Sub-Questions\n",
    "\n",
    "Our Sub-Question Query Engine breaks complex questions down into sub-questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "367f0720-97e9-4c99-9122-62f0ebbe1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "drake_index = VectorStoreIndex.from_documents(docs_drake)\n",
    "drake_query_engine = drake_index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "kendrick_index = VectorStoreIndex.from_documents(docs_kendrick)\n",
    "kendrick_query_engine = kendrick_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "169965a0-dda8-4ac3-837c-49d21ad8c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "drake_tool = QueryEngineTool(\n",
    "    drake_index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"drake_search\",\n",
    "        description=\"Useful for searching over Drake's life.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "kendrick_tool = QueryEngineTool(\n",
    "    kendrick_index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"kendrick_summary\",\n",
    "        description=\"Useful for searching over Kendrick's life.\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd544f46-7d7a-4449-af6d-3ce9bb8f632c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[drake_search] Q: Which albums did Drake release in his career?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[drake_search] A: <think>\n",
      "Okay, let's tackle this query: \"Which albums did Drake release in his career?\" Using the provided context from the two pages of the document, I need to extract all the albums mentioned.\n",
      "\n",
      "First, starting with page 6, there's a section that mentions his third studio album, \"Nothing Was the Same,\" released on September 24, 2013. It debuted at number one on the US Billboard 200. Then it mentions \"If You're Reading This It's Too Late\" released on February 12, 2015. There's a debate whether it's an album or mixtape, but the context states it's considered his fourth retail project. \n",
      "\n",
      "Next, \"What a Time to Be Alive\" is mentioned as a collaborative mixtape with Future, released on September 20, 2015. It's noted that this mixtape debuted at number one, making him the first hip-hop artist with two number-one projects in 2015. However, the heading \"2015‚Äì2017: What a Time to Be Alive, Views, and More Life\" suggests that \"Views\" and \"More Life\" are albums from that period. \n",
      "\n",
      "Looking at page 2, there's a mention of \"Virginia Black,\" but that's a bourbon whiskey, not an album. The labels listed include OVO Sound, Republic, Young Money, and Cash Money, which are relevant to his career but not albums. \n",
      "\n",
      "So compiling from page 6: \"Nothing Was the Same,\" \"If You're Reading This It's Too Late,\" \"What a Time to Be Alive\" (though labeled a mixtape), \"Views,\" and \"More Life.\" I need to confirm if all these are albums. The text refers to \"If You're Reading This...\" as a retail project, possibly an album. \"What a Time...\" is a mixtape, so maybe exclude it. But since the user asked for albums, I should focus on studio albums. \n",
      "\n",
      "The third studio album is \"Nothing Was the Same,\" then the fourth is \"If You're Reading This...\" (though debated). \"Views\" and \"More Life\" are listed under the 2015-2017 section as part of his releases. Are \"Views\" and \"More Life\" albums? \"Views\" is commonly known as an album, and \"More Life\" is sometimes called a playlist but might be considered an album in this context. \n",
      "\n",
      "Also, earlier in his career, the text mentions his second album promoted by the Club Paradise Tour, but it doesn't name it. From general knowledge, that would be \"Take Care,\" but since the user wants only based on the provided context, maybe it's not mentioned here. Wait, the context says \"his second album\" but doesn't name it. The user's context only provides \"Take Care\" as a previous work when discussing the third album's style. So \"Take Care\" is his second album. But the query is about which albums he released, and the answer should include those explicitly named in the context. \n",
      "\n",
      "Looking back: The third album is \"Nothing Was the Same,\" the fourth is \"If You're Reading This It's Too Late,\" then \"Views\" and \"More Life\" under 2015-2017. The second album isn't named here, but \"Take Care\" is mentioned as the previous work. However, the user wants only what's in the context, so maybe include \"Take Care\" as the second album. But the query is about albums he released, and the context on page 6 does mention \"Take Care\" when talking about the third album's style. So \"Take Care\" is his second album. \n",
      "\n",
      "So compiling all mentioned: \"Take Care,\" \"Nothing Was the Same,\" \"If You're Reading This It's Too Late,\" \"Views,\" and \"More Life.\" Additionally, the debut album isn't mentioned here. From the text, the first album isn't named in the provided pages. The context starts from the second album onwards. So the answer based solely on given context should list the albums explicitly named: \"Nothing Was the Same,\" \"If You're Reading This It's Too Late,\" \"Views,\" and \"More Life.\" \"Take Care\" is mentioned as a previous work but not explicitly called his second album here. Wait, the text says \"his second album\" when talking about the Club Paradise Tour. But does it name it? Let me check again. \n",
      "\n",
      "In the context: \"In promotion of his second album, Drake embarked on the worldwide Club Paradise Tour.\" But it doesn't name the album. However, later when discussing the third album, it says \"stylistically differ from Take Care,\" which implies that \"Take Care\" is the second album. So even though it's not directly stated as \"his second album Take Care,\" the context does mention \"Take Care\" in reference to the previous work. Therefore, including \"Take Care\" as the second album is correct based on the context. \n",
      "\n",
      "So the albums are:\n",
      "- Take Care (second album)\n",
      "- Nothing Was the Same (third album)\n",
      "- If You're Reading This It's Too Late (fourth album)\n",
      "- Views \n",
      "- More Life \n",
      "\n",
      "Additionally, in the section header \"2013‚Äì2015: Nothing Was the Same and If You're Reading This It's Too Late,\" those two are listed. Then \"2015‚Äì2017: What a Time to Be Alive, Views, and More Life.\" So \"Views\" and \"More Life\" are part of that period. \"What a Time to Be Alive\" is a mixtape, so maybe not included as an album. \n",
      "\n",
      "Thus, based on the context provided, the albums released by Drake are \"Take Care,\" \"Nothing Was the Same,\" \"If You're Reading This It's Too Late,\" \"Views,\" and \"More Life.\"\n",
      "</think>\n",
      "\n",
      "Based on the provided context, Drake released the following albums in his career up to the information given:\n",
      "\n",
      "1. **Take Care** (his second album, referenced when discussing stylistic differences with his third album)  \n",
      "2. **Nothing Was the Same** (third studio album, released September 24, 2013)  \n",
      "3. **If You're Reading This It's Too Late** (fourth retail project, released February 12, 2015)  \n",
      "4. **Views** (mentioned under the \"2015‚Äì2017\" period)  \n",
      "5. **More Life** (also mentioned under \"2015‚Äì2017\")  \n",
      "\n",
      "The context also references collaborative projects like *What a Time to Be Alive* (2015 mixtape with Future), but it is explicitly noted as a mixtape rather than a studio album.\n",
      "\u001b[0m<think>\n",
      "Okay, so the user wants to know which albums Drake released, based solely on the provided context. Let me make sure I get this right.\n",
      "\n",
      "First, looking at the context again on page 6. It starts talking about his third studio album, \"Nothing Was the Same,\" released in 2013. That's definitely an album. Then mentions \"If You're Reading This It's Too Late\" from 2015, which the text says is debated as an album or mixtape but is considered his fourth retail project. Since the user is asking for albums, even if there's a debate, the context refers to it as a retail project, so I should include it as an album.\n",
      "\n",
      "Next, there's \"What a Time to Be Alive\" with Future, labeled a mixtape. The user might not want mixtapes, so I should exclude that. Then under the 2015-2017 period, \"Views\" and \"More Life\" are mentioned. The headers list them, and while \"More Life\" is sometimes called a playlist, the context groups it with albums, so I'll include both as albums.\n",
      "\n",
      "Earlier, the text refers to his second album promoted by the Club Paradise Tour. It doesn't name it there, but later when discussing the third album, it mentions \"Take Care\" as the previous work. So in context, \"Take Care\" is his second album.\n",
      "\n",
      "The user's context doesn't mention his debut album, so I shouldn't include anything before \"Take Care\".\n",
      "\n",
      "So compiling the list: Take Care, Nothing Was the Same, If You're Reading This..., Views, and More Life. Even though some are debated, the context presents them as albums or major projects. Excluding the mixtape, the answer includes these five.\n",
      "</think>\n",
      "\n",
      "Based on the provided context, Drake's released albums include:  \n",
      "1. **Take Care** (second album)  \n",
      "2. **Nothing Was the Same** (third studio album, 2013)  \n",
      "3. **If You're Reading This It's Too Late** (fourth retail project, 2015)  \n",
      "4. **Views** (2016)  \n",
      "5. **More Life** (2017)  \n",
      "\n",
      "Collaborative projects like *What a Time to Be Alive* (2015) are noted as mixtapes in the context and excluded from this list. No debut album is explicitly mentioned in the provided excerpts.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    [drake_tool, kendrick_tool],\n",
    "    llm=llm_replicate,  \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"Which albums did Drake release in his career?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21d626-68e5-48f6-99f2-2f22bdc94a20",
   "metadata": {},
   "source": [
    "## 4. Text-to-SQL \n",
    "\n",
    "Here, we download and use a sample SQLite database with 11 tables, with various info about music, playlists, and customers. We will limit to a select few tables for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae86945a-5b17-4720-9827-e7c317cc3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download files\n",
    "def download_file(url, filepath):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58ea1de8-f929-4de4-a3d9-509cd128668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract SQLite database\n",
    "import requests\n",
    "import zipfile\n",
    "download_file(\"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\", \"data/chinook.zip\")\n",
    "with zipfile.ZipFile(\"data/chinook.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff40561-28ee-4762-beb8-fc110520e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///data/chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a58e4c99-bbb1-4f47-a308-951d407fde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05d460f2-c401-4738-a4be-f5a778abfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.struct_store import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"albums\", \"tracks\", \"artists\"],\n",
    "    llm=llm_replicate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf8f4ed0-82d1-4dcc-bb42-69e0794cb7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, the user is asking for some albums. Let me check the SQL query they ran. They selected the Title from the albums table, ordered by AlbumId, and limited to 5 results. The response from the database has five album titles. I need to present these in a clear and natural way.\n",
      "\n",
      "First, I'll list each album title. Since the SQL response gives them as tuples, I should extract just the title strings. Maybe number them for readability. Let me make sure there are exactly five. The titles are \"For Those About To Rock We Salute You\", \"Balls to the Wall\", \"Restless and Wild\", \"Let There Be Rock\", and \"Big Ones\". \n",
      "\n",
      "I should check if there's any specific order the user might prefer, but since the SQL used ORDER BY AlbumId, they're probably listed in the order they were added to the database, starting from the earliest. The user might just want a straightforward list. \n",
      "\n",
      "No need for additional info since the question is simply asking for some album names. I'll format the response as a numbered list to make it easy to read. Double-check for any typos or formatting issues. Looks good. The answer should be concise and directly address the query without extra fluff.\n",
      "</think>\n",
      "\n",
      "Here are five albums from the database, listed in order by their Album ID:\n",
      "\n",
      "1. **For Those About To Rock We Salute You**  \n",
      "2. **Balls to the Wall**  \n",
      "3. **Restless and Wild**  \n",
      "4. **Let There Be Rock**  \n",
      "5. **Big Ones**  \n",
      "\n",
      "Let me know if you'd like details about any of these! üéµ\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are some albums?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d13cd77-bc3d-4661-95b7-6b745f4e5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked for some artists, limited to 5. Let me check the SQL query they provided. It selects the Name from the artists table and limits to 5. The response from the database is a list of tuples like [('AC/DC',), ...]. \n",
      "\n",
      "Hmm, I need to turn that into a natural language answer. I'll start by listing the names from each tuple. Each tuple has a single element, so I can extract the first item from each. The artists are AC/DC, Accept, Aerosmith, Alanis Morissette, and Alice In Chains. Let me make sure there are exactly five as requested.\n",
      "\n",
      "I should present them in a clear format, maybe bullet points or a numbered list. Since they asked for a list, perhaps numbers would help. Also, check if any of these artists might have special characters or formatting, but they look straightforward. \n",
      "\n",
      "Wait, the user example response just has the names separated by commas. Maybe a simple sentence stating the five artists. I can phrase it like, \"Here are five artists from the database: AC/DC, Accept, Aerosmith, Alanis Morissette, and Alice In Chains.\" That's concise and matches the query's requirements. \n",
      "\n",
      "Do I need to mention that it's from the SQL query result? The example response doesn't, so maybe just present the names directly. Ensure that the limit of five is met. Yep, all five are there. No errors in the names. Alright, that should be the response.\n",
      "</think>\n",
      "\n",
      "Here are five artists from the database:  \n",
      "1. **AC/DC**  \n",
      "2. **Accept**  \n",
      "3. **Aerosmith**  \n",
      "4. **Alanis Morissette**  \n",
      "5. **Alice In Chains**\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are some artists? Limit it to 5.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3c69fe8-6692-41f3-8635-b1a438258229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out how to answer the question \"What are some tracks from the artist AC/DC? Limit it to 3\" based on the provided SQL query and its response. Let's start by understanding what the user is asking. They want three songs by AC/DC, right?\n",
      "\n",
      "Looking at the SQL query, it's selecting track names from the tracks table, joining with albums and artists to get the correct artist. The WHERE clause filters for the artist name 'AC/DC', and the LIMIT 3 ensures we only get three results. The SQL response gives three track names: 'For Those About To Rock (We Salute You)', 'Put The Finger On You', and 'Let's Get It Up'. \n",
      "\n",
      "So, the straightforward answer would be to list these three tracks. But I should check if there's any formatting needed. The user might expect a simple list, possibly with bullet points or numbers. Also, should I mention that these are three examples from their discography, or just list them plainly?\n",
      "\n",
      "Wait, the SQL response comes as a list of tuples, each containing the track name. So in the response, I should extract just the track names. The user probably doesn't need to know about the database structure, so presenting the track names in a clear manner is key. Maybe something like: \n",
      "\n",
      "\"Here are three tracks by AC/DC:\n",
      "1. For Those About To Rock (We Salute You)\n",
      "2. Put The Finger On You\n",
      "3. Let's Get It Up\"\n",
      "\n",
      "That seems clear and concise. I should also make sure that the names are written correctly, matching the SQL response exactly. No typos. Also, since the limit was 3, it's implied that there are more tracks, but the user only wanted three. The answer doesn't need to mention that unless specified. \n",
      "\n",
      "Another thing to consider: the user asked for \"some tracks\" which implies examples, so the answer meets the requirement. I think that's all. Just present the three track names in a list format.\n",
      "</think>\n",
      "\n",
      "Here are three tracks by AC/DC:  \n",
      "1. **For Those About To Rock (We Salute You)**  \n",
      "2. **Put The Finger On You**  \n",
      "3. **Let's Get It Up**  \n",
      "\n",
      "These songs showcase the band's iconic hard rock style. Let me know if you'd like more examples!\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are some tracks from the artist AC/DC? Limit it to 3\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bc73f22-9146-4e74-bcf0-562e5cafc84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT t.Name FROM tracks AS t JOIN albums AS a ON t.AlbumId = a.AlbumId JOIN artists AS ar ON a.ArtistId = ar.ArtistId WHERE ar.Name = 'AC/DC' LIMIT 3;\n"
     ]
    }
   ],
   "source": [
    "print(response.metadata[\"sql_query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3a8a8-3fd8-4638-bb72-21f5c23ea7e8",
   "metadata": {},
   "source": [
    "## 5. Structured Data Extraction\n",
    "\n",
    "An important use case for function calling is extracting structured objects. LlamaIndex provides an intuitive interface for this through `structured_predict` - simply define the target Pydantic class (can be nested), and given a prompt, we extract out the desired object.\n",
    "\n",
    "**NOTE**: Since there's no native function calling support with Llama3 / Ollama, the structured extraction is performed by prompting the LLM + output parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56bf82da-d37f-489a-8315-a620c2be45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Restaurant(BaseModel):\n",
    "    \"\"\"A restaurant with name, city, and cuisine.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    city: str\n",
    "    cuisine: str\n",
    "\n",
    "llm = llm_replicate\n",
    "\n",
    "\n",
    "prompt_tmpl = PromptTemplate(\n",
    "    \"Generate a restaurant in a given city {city_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42cfee0d-6211-44c5-b3a8-1f153adb122e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Casa Mar' city='Miami' cuisine='Nuevo Latino'\n"
     ]
    }
   ],
   "source": [
    "restaurant_obj = llm.structured_predict(\n",
    "    Restaurant, prompt_tmpl, city_name=\"Miami\"\n",
    ")\n",
    "print(restaurant_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d6334-4532-4c8d-bf12-fbbdb359f608",
   "metadata": {},
   "source": [
    "## 6. Adding Chat History to RAG (Chat Engine)\n",
    "\n",
    "In this section we create a stateful chatbot from a RAG pipeline, with our chat engine abstraction.\n",
    "\n",
    "Unlike a stateless query engine, the chat engine maintains conversation history (through a memory module like buffer memory). It performs retrieval given a condensed question, and feeds the condensed question + context + chat history into the final LLM prompt.\n",
    "\n",
    "Related resource: https://docs.llamaindex.ai/en/stable/examples/chat_engine/chat_engine_condense_plus_context/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f5fd638-c1b2-41e6-8650-33d4ecb98c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
    "    index.as_retriever(),\n",
    "    memory=memory,\n",
    "    llm=llm_replicate,\n",
    "    context_prompt=(\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
    "        \" about the Kendrick and Drake beef.\"\n",
    "        \"Here are the relevant documents for the context:\\n\"\n",
    "        \"{context_str}\"\n",
    "        \"\\nInstruction: Use the previous chat history, or the context above, to interact and help the user.\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad1c014b-9c85-4db0-9234-9b41963bcef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condensed question: Tell me about the songs Drake released in the beef.\n",
      "<think>\n",
      "Okay, the user is asking about the songs Drake released during his beef with Kendrick Lamar. I need to pull the relevant info from the provided documents. Let's check the context again.\n",
      "\n",
      "The documents mention two specific instances. On page 28, there's a detailed section about Drake's \"The Heart Part 6\" released on May 5. It explains that Drake responded to Kendrick's tracks, using a similar title to Kendrick's \"The Heart\" series. The song samples Aretha Franklin, addresses Kendrick's accusations, and includes rebuttals to \"Not Like Us.\" It also notes that Drake seems a bit over the beef but still hints at escalation.\n",
      "\n",
      "Looking through the context, those are the main tracks mentioned. The other page (31) talks about Shaboozey‚Äôs Cowboy Carter features but that's not related to Drake's songs. So, the key song here is \"The Heart Part 6.\" The user might be expecting more songs, but based on the given documents, only this one is detailed. I should mention it clearly, explain the context, the references to Kendrick's work, and maybe note that the response was rapid, written within 24 hours. Also, highlight Drake's strategy of mirroring Kendrick's style with soul samples and series titles. Make sure to answer accurately without adding info outside the provided context. Got it.\n",
      "</think>\n",
      "\n",
      "In the Kendrick Lamar/Drake beef, Drake released **\"The Heart Part 6\"** on May 5 as a direct response to Kendrick‚Äôs diss tracks. Here‚Äôs the breakdown:  \n",
      "\n",
      "- **Title & Strategy**: Drake co-opted Kendrick‚Äôs recurring series \"The Heart\" (Kendrick‚Äôs last was \"The Heart Part 5\"), mirroring his rival‚Äôs tactic of using soulful, conceptual titles.  \n",
      "- **Sound**: The track samples Aretha Franklin‚Äôs ‚ÄúProve It,‚Äù countering Kendrick‚Äôs use of Teddy Pendergrass and Al Green samples in earlier disses.  \n",
      "- **Content**: Drake dismisses Kendrick‚Äôs accusations as baseless, addresses claims from ‚ÄúNot Like Us,‚Äù and suggests he‚Äôs prepared to escalate the feud (‚Äúshit is about to get dark‚Äù). He also implies the track was written rapidly in the last 24 hours, reflecting the breakneck pace of the beef.  \n",
      "- **Tone**: Drake sounds weary but defiant, balancing dismissiveness with lingering threats.  \n",
      "\n",
      "This was Drake‚Äôs sharpest rebuttal in the feud, though Kendrick ultimately dominated the narrative with tracks like ‚ÄúNot Like Us.‚Äù Let me know if you want deeper analysis!\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\n",
    "    \"Tell me about the songs Drake released in the beef.\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d9ea94-5234-4c24-94d0-c0df80b41c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condensed question: <think>\n",
      "Alright, the user initially asked about Drake's songs in the beef, and the assistant replied focusing on \"The Heart Part 6.\" Now the follow-up is \"What about Kendrick?\" The user wants to know about Kendrick's side of the diss tracks.\n",
      "\n",
      "To make this a standalone question, I need to reference the previous topic (Drake's songs in the beef) and then specify Kendrick's role. The original answer mentioned Kendrick's tracks like \"Not Like Us,\" so the standalone question should ask for details on Kendrick's diss tracks in the same feud. The key is to maintain context without relying on the chat history.\n",
      "\n",
      "So, \"What diss tracks did Kendrick Lamar release in his feud with Drake?\" would work. It's clear, standalone, and ties directly to the prior discussion about Drake's releases.\n",
      "</think>\n",
      "\n",
      "**Standalone question:**  \n",
      "\"What diss tracks did Kendrick Lamar release in his feud with Drake?\"\n",
      "<think>\n",
      "Okay, the user just asked, \"What about Kendrick?\" after I explained Drake's songs. They probably want to know about Kendrick's diss tracks in the same beef. Let me check the provided context again.\n",
      "\n",
      "From the previous context, there's mention of Kendrick's \"Euphoria\" released on April 30, which is a six-minute diss track against Drake. The documents also reference \"Not Like Us\" and \"Like That,\" where Kendrick takes shots at Drake. The \"Like That\" verse from Kendrick started the beef by dismissing Drake and J. Cole's \"First Person Shooter\" collab. Then \"Euphoria\" directly attacks Drake's credibility, accusations about his parenting, and other personal jabs. \"Not Like Us\" escalates with serious allegations, calling Drake a predator and questioning his associations. \n",
      "\n",
      "I need to structure the response by listing each of Kendrick's tracks in order, explain their content, strategies, and impact compared to Drake's. Also, note how Kendrick's tracks were more impactful in the public eye, especially \"Not Like Us\" becoming a cultural moment. Make sure to highlight Kendrick's aggressive lyrical approach and the effectiveness of his disses. Avoid including any information not in the context, like other songs not mentioned here. Keep it clear and concise, maybe bullet points for each track with key points. Also, mention how Kendrick's tracks dominated the narrative despite Drake's efforts. That should answer the user's query properly.\n",
      "</think>\n",
      "\n",
      "Kendrick Lamar fired back at Drake with **three explosive diss tracks**, each escalating in intensity and impact. Here‚Äôs the rundown:  \n",
      "\n",
      "### 1. **\"Like That\"** (March 2024)  \n",
      "- **Context**: A featured verse on *Future & Metro Boomin‚Äôs* album, directly responding to Drake and J. Cole‚Äôs *\"First Person Shooter\"* collab (where Cole called himself, Drake, and Kendrick the \"Big Three\").  \n",
      "- **Key Lines**: *\"It‚Äôs just big me / Motherfuck the Big Three‚ÄîN***a, it‚Äôs just big me\"*  \n",
      "- **Strategy**: Kendrick rejected the idea of a \"Big Three,\" positioning himself as the undisputed top dog.  \n",
      "\n",
      "### 2. **\"Euphoria\"** (April 30)  \n",
      "- A **six-minute** barrage where Kendrick:  \n",
      "  - Mocks Drake‚Äôs use of A.I. Tupac vocals (*\"Somebody had told me you got a ring, on God, I‚Äôm ready to double the wage / I‚Äôd rather do that than let a Canadian n***a make Pac turn in his grave\"*).  \n",
      "  - Questions Drake‚Äôs authenticity (*\"When you see me, call me Christopher Wallace / You rappin‚Äô to n***as like you‚Äôs the one that‚Äôs hittin‚Äô the boy\"*).  \n",
      "  - Attacks his parenting (*\"I got a son to raise, but I can see you don‚Äôt know nothin‚Äô ‚Äòbout that\"*).  \n",
      "\n",
      "### 3. **\"Not Like Us\"** (May 4)  \n",
      "- **The Nuclear Bomb**: A scathing, club-ready diss accusing Drake of predatory behavior and hypocrisy:  \n",
      "  - *\"Certified Lover Boy? Certified pedophile\"*  \n",
      "  - *\"Why you trollin‚Äô like a bitch? Ain‚Äôt you tired? / Tryna strike a chord, and it‚Äôs probably A-minor\"*  \n",
      "  - **Impact**: The track became a cultural phenomenon, topping charts and sparking memes (e.g., *\"OV-Hoe\"*).  \n",
      "\n",
      "### **Key Tactics**:  \n",
      "- **Aggressive Wordplay**: Kendrick weaponized Drake‚Äôs past controversies (e.g., relationships with younger women).  \n",
      "- **Cultural Resonance**: \"Not Like Us\" framed Drake as an outsider to hip-hop authenticity, while Kendrick positioned himself as its defender.  \n",
      "\n",
      "While Drake‚Äôs responses (e.g., *\"Push Ups,\" \"Taylor Made,\" \"The Heart Part 6\"*) were strategic, **Kendrick‚Äôs tracks dominated the narrative**‚Äîespecially \"Not Like Us,\" which many consider the knockout blow. Need more specifics? Let me know!\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"What about Kendrick?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5d92b-81e8-4aa6-b31d-3a87adf39cd5",
   "metadata": {},
   "source": [
    "## 7. Agents\n",
    "\n",
    "Here we build agents with Llama 3. We perform RAG over simple functions as well as the documents above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703d2f5-d126-45bc-812a-ba6d9d38225f",
   "metadata": {},
   "source": [
    "### Agents And Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df59fa8b-94f5-4e34-9f59-8a2307272f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab77195-bc48-47b5-b780-bb311ab8cd21",
   "metadata": {},
   "source": [
    "### Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2661258-c92d-4969-8b00-5085c0c43ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two integers and returns the result integer\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divides two integers and returns the result integer\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
    "divide_tool = FunctionTool.from_defaults(fn=divide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b7eac-f064-4b6e-824a-5000f23b8b28",
   "metadata": {},
   "source": [
    "### ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce6d7f65-1275-4fac-a132-7b1c6a151894",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    [multiply_tool, add_tool, subtract_tool, divide_tool],\n",
    "    llm=llm_replicate,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0904b9-c9a1-4aa7-9b94-6557197b43eb",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "736ff7e8-b8ac-4eb0-b11b-5f60dbc32f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 52818ee2-0995-4193-8390-130bbb49b328. Step input: What is (121 + 2) * 5?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: add\n",
      "Action Input: {'a': 121, 'b': 2}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 123\n",
      "\u001b[0m> Running step 76e625d4-45e4-4790-b88d-1a582792cc7f. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: multiply\n",
      "Action Input: {'a': 123, 'b': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 615\n",
      "\u001b[0m> Running step 36211765-2185-4a3c-a4fa-f19744590fa5. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The result of (121 + 2) * 5 is 615.\n",
      "\u001b[0mThe result of (121 + 2) * 5 is 615.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is (121 + 2) * 5?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a4103-11f2-4aee-8c45-092abe17c4c4",
   "metadata": {},
   "source": [
    "### ReAct Agent With RAG QueryEngine Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2caff98-7653-4517-9374-d145306b8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070edadd-bc94-463c-bd12-36f2515dcad1",
   "metadata": {},
   "source": [
    "### Create ReAct Agent using RAG QueryEngine Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35c9bef7-554f-41a1-8b09-ccb2bfc00b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drake_tool = QueryEngineTool(\n",
    "    drake_index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"drake_search\",\n",
    "        description=\"Useful for searching over Drake's life.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "kendrick_tool = QueryEngineTool(\n",
    "    kendrick_index.as_query_engine(),\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"kendrick_search\",\n",
    "        description=\"Useful for searching over Kendrick's life.\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "query_engine_tools = [drake_tool, kendrick_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2db1c27d-2d0b-47db-8a7f-1f86e5bd6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,  ## TODO: define query tools\n",
    "    llm=llm_replicate,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e26ad-002a-4f61-98e5-81adbcd64758",
   "metadata": {},
   "source": [
    "### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18dd1db0-f469-4c9a-b107-80369e0f9c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step c7b40d9f-f06e-484b-aa58-e4c6f030c804. Step input: Tell me about how Kendrick and Drake grew up\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: kendrick_search\n",
      "Action Input: {'input': 'early life and upbringing'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: <think>\n",
      "Okay, let's tackle this query about Kendrick Lamar's early life and upbringing using the provided context. First, I need to make sure I cover all the relevant points from the text.\n",
      "\n",
      "The user is asking about his early life, so I should start with his education. The context mentions Centennial High School, where his nickname was \"Man-Man\" because of his precocious behavior. That's an interesting detail to include. He was a quiet, observant student who did well academically but had a stutter. His first-grade teacher at Robert E. McNair Elementary encouraged him to write after he used the word \"audacity\" correctly. That's a good point about his early encouragement in writing.\n",
      "\n",
      "Then, in seventh grade at Vanguard Learning Center, his English teacher Regis Inge introduced him to poetry, linking it to hip hop. The teacher used poetry to address racial tensions among students. This exposure made Kendrick love songwriting, as he could express his feelings through writing. He wrote lyrics instead of doing other class assignments, which shows his dedication early on. His early writings were profane but helped him cope with psychological trauma and depression during adolescence. Inge helped him improve by critiquing his language and giving prompts.\n",
      "\n",
      "Moving to high school, he attended Centennial again. He failed PE in ninth grade and had to go to summer school in tenth grade, where he got caught in a gang war. Despite trying to avoid gangs, he got involved in Compton's gang culture, leading to violence, health issues, and police encounters. His father intervened, which made him distance himself from that lifestyle. At 16, he converted to Christianity after a friend's death and started a relationship with Whitney Alford, though they faced issues due to his sex addiction and infidelity. He graduated in 2006 with straight As and considered studying psychology and astronomy but chose music instead.\n",
      "\n",
      "Also, during high school, he used the stage name K.Dot, started freestyling, and met Dave Free. They collaborated, recording music in various places. His first mixtape came out during his senior year.\n",
      "\n",
      "Other mentions include sources like LA Weekly, Complex, HipHopDX, and The New York Times, but those are references so probably not needed in the answer unless asked. Also, details about his mixtapes and career beginnings might be more about his career than upbringing, so maybe focus on the early life parts.\n",
      "\n",
      "I need to structure this answer chronologically, starting from elementary school through high school, highlighting key influences, challenges, and turning points. Make sure to mention his academic achievements, struggles with gang involvement, family intervention, conversion to Christianity, and decision to pursue music over college. Also, note the teachers who influenced his writing and how he started in music with Dave Free.\n",
      "</think>\n",
      "\n",
      "Kendrick Lamar's early life and upbringing were marked by academic achievement, artistic development, and challenges with gang influences. Growing up in Compton, he attended Robert E. McNair Elementary School, where a first-grade teacher recognized his writing potential after he correctly used the word \"audacity.\" In seventh grade at Vanguard Learning Center, English teacher Regis Inge introduced him to poetry as a tool to address racial tensions, sparking Lamar's passion for songwriting. He used writing to process psychological trauma and depression, often neglecting other classwork to scribe lyrics in notebooks.  \n",
      "\n",
      "At Centennial High School, Lamar (nicknamed \"Man-Man\") maintained straight-A academics but struggled socially, with a stutter and experiences of gang entanglements. He failed ninth-grade physical education and faced gang violence during summer school. His father later intervened to pull him away from Compton's gang culture, which had led to police encounters and health scares. A pivotal moment occurred at 16 when he converted to Christianity after a friend's death.  \n",
      "\n",
      "Romantically involved with classmate Whitney Alford, their relationship faced challenges due to Lamar's sex addiction and infidelity. Despite considering college studies in psychology/astronomy, he prioritized music after graduating in 2006. Adopting the stage name K.Dot, he began freestyling and collaborating with friend Dave Free, recording mixtapes (including his debut during senior year) in makeshift studios. These experiences laid the foundation for his career, blending intellectual growth with the raw realities of Compton life.\n",
      "\u001b[0m> Running step 188ec595-0290-42e4-a78c-92c13f1f5f83. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: drake_search\n",
      "Action Input: {'input': 'early life and upbringing'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: <think>\n",
      "Okay, let me start by understanding the user's query. They want information about Drake's early life and upbringing based on the provided context. The context has two pages from a PDF, labeled page 3 and page 29.\n",
      "\n",
      "First, I'll focus on page 3. It mentions that Drake was raised in two neighborhoods: Weston Road in Toronto's working-class west end until grade six, and then moved to Forest Hill in 2000. He attended Weston Memorial Junior Public School until grade four and played minor hockey. However, he left hockey after an injury from a cross-check. The move to Forest Hill wasn't luxurious; they lived in a basement and first floor of a shared house. He went to Forest Hill Collegiate Institute and Vaughan Road Academy, which he found tough. He worked at his grandfather's furniture factory and faced bullying. He dropped out of school to focus on acting, later getting his diploma in 2012. At 15, he got into acting through a friend's father, landing a role on Degrassi. He started music early, releasing mixtapes and performing by 2006.\n",
      "\n",
      "Page 29 has references, which support the prior info but don't add new details. For example, references 29, 33-43, 44-50 are cited in page 3's text, providing sources for his schooling, hockey, moving, acting career, etc.\n",
      "\n",
      "I need to structure the answer chronologically, highlighting neighborhoods, education, challenges (bullying, family financial struggles), early career (acting and music). Also, note dropping out but eventually getting his diploma. Make sure to include the move from Weston Road to Forest Hill, the reasons for leaving hockey, and his initial steps in both acting and music. Avoid adding info not in the context, like later career achievements not mentioned here. Use quotes where possible, like his comment about their living situation in Forest Hill. Check that all points are covered from the context without assumptions.\n",
      "</think>\n",
      "\n",
      "Drake's early life and upbringing were marked by a mix of working-class roots, educational challenges, and early career pursuits:  \n",
      "\n",
      "### **Neighborhoods & Family Background**  \n",
      "- **Weston Road (Toronto)**: Drake spent his childhood in this working-class area until grade six, attending Weston Memorial Junior Public School until grade four. He played minor hockey with the Weston Red Wings but left after a serious neck injury from a cross-check during a game.  \n",
      "- **Forest Hill**: In 2000, his family moved to this affluent Toronto neighborhood, though they lived modestly in a shared house. Drake clarified, \"It was not big, not luxurious. It was what we could afford,\" describing their half-house arrangement (basement and first floor).  \n",
      "\n",
      "### **Education**  \n",
      "- Attended **Forest Hill Collegiate Institute** and later **Vaughan Road Academy** in a multicultural area, which he described as challenging.  \n",
      "- Struggled with bullying due to his racial and religious background.  \n",
      "- Dropped out of high school to focus on acting but earned his diploma in October 2012.  \n",
      "\n",
      "### **Early Career Beginnings**  \n",
      "- **Acting**: At 15, an acting agent connected him to *Degrassi: The Next Generation*, where he portrayed Jimmy Brooks, a disabled basketball star. He balanced acting with late-night music recording sessions, often sleeping on set.  \n",
      "- **Music**: Inspired by Jay-Z and Clipse, he self-released his debut mixtape *Room for Improvement* (2006), selling 6,000 copies. His first concert (opening for Ice Cube) earned him $100.  \n",
      "\n",
      "### **Challenges**  \n",
      "- Financial hardship: He worked at his grandfather‚Äôs furniture factory as a teen and later stated, \"My mother was very sick. We were very poor, like broke. The only money I had coming in was [from] Canadian TV.\"  \n",
      "\n",
      "This period laid the groundwork for his dual career in entertainment, blending resilience, family struggles, and early artistic ambition.\n",
      "\u001b[0m> Running step 346ad109-6769-4e21-bab3-522ae4b6924c. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: <think>\n",
      "Okay, the user asked about how both Kendrick Lamar and Drake grew up. I've already searched for Kendrick's early life and upbringing using the kendrick_search tool, which provided a detailed background about his education, family, challenges with gangs, and early music career. Then, I used the drake_search tool to get information on Drake's upbringing, covering his neighborhoods, education, family struggles, and early steps into acting and music.\n",
      "\n",
      "Now, I need to combine both sets of information into a coherent answer that addresses their upbringings side by side. I should structure the answer to highlight similarities and differences. \n",
      "\n",
      "For Kendrick, key points are growing up in Compton, academic achievements, influence from teachers, gang involvement, conversion to Christianity, and early music endeavors. For Drake, important aspects are moving between neighborhoods in Toronto, educational challenges, early acting career, family financial struggles, and his initial steps in music.\n",
      "\n",
      "I should present each artist's background in separate sections or paragraphs, ensuring clarity. I need to make sure to mention the locations they grew up in, family influences, educational experiences, early career choices, and any significant challenges they faced during their upbringing. Also, note how their environments (Compton vs. Toronto) shaped their early lives and career paths.\n",
      "\n",
      "Avoid mixing the two narratives to prevent confusion. Use clear transitions between the two artists. Check that all important details from the tool observations are included, and present the answer in English as per the user's question.\n",
      "</think>\n",
      "\n",
      "**Kendrick Lamar** and **Drake** had distinct upbringings that shaped their artistic paths:  \n",
      "\n",
      "### **Kendrick Lamar**  \n",
      "- **Location**: Grew up in Compton, California, a city notorious for gang culture.  \n",
      "- **Family & Education**:  \n",
      "  - Encouraged by teachers early; his first-grade mentor recognized his writing talent after he used \"audacity\" correctly.  \n",
      "  - In seventh grade, an English teacher connected poetry to hip hop, sparking his songwriting passion.  \n",
      "  - Excelled academically (straight-A student) but faced social struggles, including a stutter.  \n",
      "- **Challenges**:  \n",
      "  - Got entangled in gang violence during high school, leading to police encounters and health scares. His father intervened to pull him away.  \n",
      "  - Converted to Christianity at 16 after a friend‚Äôs death.  \n",
      "- **Music Beginnings**:  \n",
      "  - Started as \"K.Dot,\" freestyling and collaborating with friend Dave Free. Recorded mixtapes in makeshift studios during high school.  \n",
      "\n",
      "### **Drake**  \n",
      "- **Location**: Raised in Toronto, Canada‚Äîfirst in working-class Weston Road, later in affluent Forest Hill (though his family lived modestly).  \n",
      "- **Family & Education**:  \n",
      "  - Parents divorced young; mother struggled with illness, leading to financial hardship.  \n",
      "  - Attended multiple schools, faced bullying, and dropped out of high school (later earned his diploma in 2012).  \n",
      "- **Early Careers**:  \n",
      "  - **Acting**: Landed a role on *Degrassi: The Next Generation* at 15, balancing acting with music.  \n",
      "  - **Music**: Released his first mixtape *Room for Improvement* in 2006, selling copies independently.  \n",
      "- **Challenges**:  \n",
      "  - Worked at his grandfather‚Äôs furniture factory as a teen. Later admitted, \"We were very poor... The only money I had coming in was [from] Canadian TV.\"  \n",
      "\n",
      "### **Contrasts**:  \n",
      "- **Environment**: Kendrick‚Äôs Compton upbringing exposed him to systemic violence, while Drake navigated class disparities in Toronto.  \n",
      "- **Artistic Spark**: Kendrick found purpose in writing to process trauma, whereas Drake juggled acting and music amid financial instability.  \n",
      "- **Education**: Both faced academic challenges, but Kendrick maintained high grades, while Drake prioritized creative pursuits over schooling early on.  \n",
      "\n",
      "Their contrasting experiences‚ÄîKendrick‚Äôs immersion in Compton‚Äôs struggles vs. Drake‚Äôs hustle across Toronto‚Äôs socioeconomic divides‚Äîbecame foundational to their lyrical themes and career trajectories.\n",
      "\u001b[0m<think>\n",
      "Okay, the user asked about how both Kendrick Lamar and Drake grew up. I've already searched for Kendrick's early life and upbringing using the kendrick_search tool, which provided a detailed background about his education, family, challenges with gangs, and early music career. Then, I used the drake_search tool to get information on Drake's upbringing, covering his neighborhoods, education, family struggles, and early steps into acting and music.\n",
      "\n",
      "Now, I need to combine both sets of information into a coherent answer that addresses their upbringings side by side. I should structure the answer to highlight similarities and differences. \n",
      "\n",
      "For Kendrick, key points are growing up in Compton, academic achievements, influence from teachers, gang involvement, conversion to Christianity, and early music endeavors. For Drake, important aspects are moving between neighborhoods in Toronto, educational challenges, early acting career, family financial struggles, and his initial steps in music.\n",
      "\n",
      "I should present each artist's background in separate sections or paragraphs, ensuring clarity. I need to make sure to mention the locations they grew up in, family influences, educational experiences, early career choices, and any significant challenges they faced during their upbringing. Also, note how their environments (Compton vs. Toronto) shaped their early lives and career paths.\n",
      "\n",
      "Avoid mixing the two narratives to prevent confusion. Use clear transitions between the two artists. Check that all important details from the tool observations are included, and present the answer in English as per the user's question.\n",
      "</think>\n",
      "\n",
      "**Kendrick Lamar** and **Drake** had distinct upbringings that shaped their artistic paths:  \n",
      "\n",
      "### **Kendrick Lamar**  \n",
      "- **Location**: Grew up in Compton, California, a city notorious for gang culture.  \n",
      "- **Family & Education**:  \n",
      "  - Encouraged by teachers early; his first-grade mentor recognized his writing talent after he used \"audacity\" correctly.  \n",
      "  - In seventh grade, an English teacher connected poetry to hip hop, sparking his songwriting passion.  \n",
      "  - Excelled academically (straight-A student) but faced social struggles, including a stutter.  \n",
      "- **Challenges**:  \n",
      "  - Got entangled in gang violence during high school, leading to police encounters and health scares. His father intervened to pull him away.  \n",
      "  - Converted to Christianity at 16 after a friend‚Äôs death.  \n",
      "- **Music Beginnings**:  \n",
      "  - Started as \"K.Dot,\" freestyling and collaborating with friend Dave Free. Recorded mixtapes in makeshift studios during high school.  \n",
      "\n",
      "### **Drake**  \n",
      "- **Location**: Raised in Toronto, Canada‚Äîfirst in working-class Weston Road, later in affluent Forest Hill (though his family lived modestly).  \n",
      "- **Family & Education**:  \n",
      "  - Parents divorced young; mother struggled with illness, leading to financial hardship.  \n",
      "  - Attended multiple schools, faced bullying, and dropped out of high school (later earned his diploma in 2012).  \n",
      "- **Early Careers**:  \n",
      "  - **Acting**: Landed a role on *Degrassi: The Next Generation* at 15, balancing acting with music.  \n",
      "  - **Music**: Released his first mixtape *Room for Improvement* in 2006, selling copies independently.  \n",
      "- **Challenges**:  \n",
      "  - Worked at his grandfather‚Äôs furniture factory as a teen. Later admitted, \"We were very poor... The only money I had coming in was [from] Canadian TV.\"  \n",
      "\n",
      "### **Contrasts**:  \n",
      "- **Environment**: Kendrick‚Äôs Compton upbringing exposed him to systemic violence, while Drake navigated class disparities in Toronto.  \n",
      "- **Artistic Spark**: Kendrick found purpose in writing to process trauma, whereas Drake juggled acting and music amid financial instability.  \n",
      "- **Education**: Both faced academic challenges, but Kendrick maintained high grades, while Drake prioritized creative pursuits over schooling early on.  \n",
      "\n",
      "Their contrasting experiences‚ÄîKendrick‚Äôs immersion in Compton‚Äôs struggles vs. Drake‚Äôs hustle across Toronto‚Äôs socioeconomic divides‚Äîbecame foundational to their lyrical themes and career trajectories.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me about how Kendrick and Drake grew up\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b3a38-2ffd-4a42-b6d0-cece0002b66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_lab_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
