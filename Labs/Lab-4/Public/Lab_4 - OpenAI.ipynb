{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0419eeda-5f05-414b-b266-12cf666bb0dc",
   "metadata": {},
   "source": [
    "# üî¨ Virtual Lab 4: Running OpenAI Models on LlamaIndex & LangChain  \n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; padding: 15px; border-radius: 10px; background-color: #f4f4f4;\">\n",
    "\n",
    "### üöÄ **Platform**  \n",
    "**OpenAI**  \n",
    "\n",
    "### üè∑Ô∏è **Models Used**  \n",
    "- **gpt-4o-mini**  \n",
    "- **gpt-3.5-turbo**  \n",
    "\n",
    "### üõ†Ô∏è **Frameworks Used**  \n",
    "- **LlamaIndex**  \n",
    "- **LangChain / LangGraph**  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf13cc10-1ccd-47a6-8531-ffe601663ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: pypdf2\n",
      "Successfully installed pypdf2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3213d8d1-c312-4034-b2b7-26ddf0c947cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: PyPDF2\n",
      "Version: 3.0.1\n",
      "Summary: A pure-python PDF library capable of splitting, merging, cropping, and transforming PDF files\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Mathieu Fenniak <biziqe@mathieu.fenniak.net>\n",
      "License: \n",
      "Location: /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5af0ee3-e705-40f0-adff-2274ca129d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: openai in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (1.65.2)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.2.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.40-py3-none-any.whl (414 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.11-py3-none-any.whl (335 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl (633 kB)\n",
      "Installing collected packages: zstandard, orjson, jsonpointer, requests-toolbelt, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.19 langchain-core-0.3.40 langchain-text-splitters-0.3.6 langsmith-0.3.11 orjson-3.10.15 requests-toolbelt-1.0.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-core openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56de6bac-c168-4ba2-9c79-d508f6e21aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.3.40)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.3.19)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.3.11)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (2.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.19->langchain-community) (0.3.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.19->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.37->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Installing collected packages: httpx-sse, pydantic-settings, langchain-community\n",
      "Successfully installed httpx-sse-0.4.0 langchain-community-0.3.18 pydantic-settings-2.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a73c39e-b93c-4fc7-bebf-4cb7726a4dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.3.40)\n",
      "Requirement already satisfied: openai in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (1.65.2)\n",
      "Requirement already satisfied: langchain-community in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-core openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e016a4a8-1f32-4174-b29f-7db1dc0fc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain-core in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.3.40)\n",
      "Requirement already satisfied: langchain-community in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (0.3.18)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-openai) (1.65.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain) (2.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/denesh/Desktop/IIT-Chicago/Sem-3/SPM/VirtualLabs/Lab_4/venv_lab_4/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-openai langchain langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72dab26e-d096-439f-870f-87b60320e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "import zipfile\n",
    "import sqlite3\n",
    "import json\n",
    "from sqlalchemy import create_engine, text\n",
    "from pydantic import BaseModel\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a5225-2163-4956-bdd0-6870637fa6f4",
   "metadata": {},
   "source": [
    "### OpenAI API Setup & Configuration\n",
    "\n",
    "In this section, we set up the OpenAI API client and define a function (`call_gpt`)  \n",
    "to interact with **GPT-4o Mini**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec33522-ec93-4059-9fc8-67c65ee1868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API Key\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"add-your-api-key\"\n",
    "from Constants import Constants\n",
    "openai.api_key = Constants.OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39c71b6-c9d8-4c29-8998-c72488bf6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=Constants.OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39577861-f2d6-4d82-bc93-67408b79d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global model configuration\n",
    "llm_config = {\"model\": \"gpt-4o-mini\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc9ff83-8144-4c27-b139-cbda7d365d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call complete with a prompt\n",
    "def call_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342297b1-0c64-499b-8e12-7a25a6bd4482",
   "metadata": {},
   "source": [
    "### Document Download & Text Extraction\n",
    "\n",
    "This section downloads PDF documents related to **Drake and Kendrick Lamar**,  \n",
    "extracts their text content, and loads them for further processing.\n",
    "\n",
    "- **Download PDFs**: Fetches the documents from Dropbox and saves them locally.  \n",
    "- **Extract Text**: Reads the PDFs using `PyPDF2` and converts them into plain text.  \n",
    "- **Load Documents**: Stores the extracted text in variables (`docs_kendrick`, `docs_drake`, `docs_both`)  \n",
    "  for querying and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5347eb19-bf0d-44fb-9223-23ccce7f15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download PDFs\n",
    "def download_file(url, filepath):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9aaf5b1-c967-4664-8ceb-cc9a1d79b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download documents\n",
    "pdf_urls = {\n",
    "    \"drake_kendrick_beef\": \"https://www.dropbox.com/scl/fi/t1soxfjdp0v44an6sdymd/drake_kendrick_beef.pdf?rlkey=u9546ymb7fj8lk2v64r6p5r5k&st=wjzzrgil&dl=1\",\n",
    "    \"drake\": \"https://www.dropbox.com/scl/fi/nts3n64s6kymner2jppd6/drake.pdf?rlkey=hksirpqwzlzqoejn55zemk6ld&st=mohyfyh4&dl=1\",\n",
    "    \"kendrick\": \"https://www.dropbox.com/scl/fi/8ax2vnoebhmy44bes2n1d/kendrick.pdf?rlkey=fhxvn94t5amdqcv9vshifd3hj&st=dxdtytn6&dl=1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8877df1a-110c-4b79-bb96-89b8bcca69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in pdf_urls.items():\n",
    "    download_file(url, f\"data/{name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ae8f00-1e46-4c66-a864-b06c53e6bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdf(filepath):\n",
    "    with open(filepath, \"rb\") as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = \"\\n\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7466e134-2909-47b1-8334-7638f1274390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "docs = {\n",
    "    \"drake_kendrick_beef\": extract_text_from_pdf(\"data/drake_kendrick_beef.pdf\"),\n",
    "    \"drake\": extract_text_from_pdf(\"data/drake.pdf\"),\n",
    "    \"kendrick\": extract_text_from_pdf(\"data/kendrick.pdf\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5778d100-d91f-4b28-8473-295338991e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI Embeddings and Vector Store\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key= Constants.OPENAI_API_KEY)\n",
    "vector_store = InMemoryVectorStore(embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd346aad-4728-4242-8f60-f78e2dd0c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x133b92ed0>\n"
     ]
    }
   ],
   "source": [
    "# Add documents to vector store \n",
    "for name, text in docs.items():\n",
    "    doc = Document(page_content=text, metadata={\"source\": name})\n",
    "    vector_store.add_documents([doc])  # Remove embedding_model from here\n",
    "\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b926791-ae0e-4e61-ab65-5ca30e177234",
   "metadata": {},
   "source": [
    "### Basic GPT-4o Mini Query & Streaming Response\n",
    "\n",
    "This section demonstrates how to interact with **GPT-4o Mini** using both standard  \n",
    "and streaming responses.\n",
    "\n",
    "- **Basic Completion**: Calls `call_gpt()` to get a simple text-based response.  \n",
    "- **Streaming Response**: Uses `stream_gpt()` to receive output in real-time,  \n",
    "  printing the response incrementally as it's generated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9632be3-327b-4723-b9c0-07f12788a0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have personal preferences, but I can tell you that both Drake and Kendrick Lamar have made significant impacts on the music industry. Drake is known for his catchy hooks and versatility across genres, while Kendrick is celebrated for his lyrical depth and storytelling. Fans often have strong opinions about both artists, and their styles cater to different tastes. Who do you prefer?\n"
     ]
    }
   ],
   "source": [
    "response = call_gpt(\"Do you like Drake or Kendrick better?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a7856c0-4a0e-4806-bcc0-dcc191bbad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Drake fan, I appreciate his versatility and ability to blend different genres seamlessly. Drake has a unique talent for crafting catchy hooks and relatable lyrics that resonate with a wide audience. His storytelling often reflects personal experiences, making his music feel authentic and accessible.\n",
      "\n",
      "Additionally, Drake excels in creating memorable collaborations and has a knack for tapping into current trends, which keeps his sound fresh. His ability to switch between rap and singing allows him to explore a range of emotions and themes, from introspection to celebration.\n",
      "\n",
      "While Kendrick Lamar is undoubtedly a brilliant artist with profound lyrical depth and social commentary, I find that Drake‚Äôs emphasis on vibe, melody, and catchy production aligns more with my personal taste. His music often feels like the soundtrack to various moments in life, whether it‚Äôs a party, a late-night drive, or a reflective moment. Ultimately, it comes down to a preference for the feel and flow of Drake's music.None"
     ]
    }
   ],
   "source": [
    "# Streaming response\n",
    "def stream_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in response:\n",
    "        if chunk.choices:\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "stream_gpt(\"You're a Drake fan. Tell me why you like Drake more than Kendrick.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c62d3-12c0-4e9a-add4-83d65af47e57",
   "metadata": {},
   "source": [
    "### Multi-Turn Chat with GPT-4o Mini\n",
    "\n",
    "This section demonstrates **structured conversations** with GPT-4o Mini using a list of messages.\n",
    "\n",
    "- **Role-Based Messages**: The model is assigned a **system role** (e.g., acting as Kendrick).  \n",
    "- **User Interaction**: The user provides an input query, and GPT-4o Mini generates a response.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bda4662-b0cb-4d62-b7ec-83b0a2d3fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call chat with a list of messages\n",
    "def chat_with_gpt(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Kendrick.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a verse.\"},\n",
    "]\n",
    "response = chat_with_gpt(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d800a9a4-4a9b-4b96-bea6-5ab7ce4a6a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here‚Äôs a verse for you:\n",
      "\n",
      "In the city lights, where dreams collide,  \n",
      "Chasing shadows, never let them slide,  \n",
      "Heartbeats echo in the midnight air,  \n",
      "Rising from the struggle, yeah, we‚Äôre almost there.  \n",
      "\n",
      "Every scar a story, every tear a fight,  \n",
      "Painting life in colors, turning dark to bright,  \n",
      "With the fire in my soul, I‚Äôm breaking through the chains,  \n",
      "Building empires from the ashes, dancing in the rain.  \n",
      "\n",
      "Hope you like it!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea0f80e-1fd8-4f11-84a9-7ee6d19b0b5f",
   "metadata": {},
   "source": [
    "### Basic RAG (Retrieval-Augmented Generation) - Vector Search\n",
    "\n",
    "This section demonstrates **retrieving and answering questions** from documents  \n",
    "using **GPT-4o Mini**.\n",
    "\n",
    "- **Query-Based Search**: Uses `query_rag()` to fetch relevant information from the document.  \n",
    "- **Contextual Responses**: The model is provided with document content to generate informed answers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5de748f7-45d6-470a-957a-68b7f6d8cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag_with_embedding(prompt, top_k=3, max_tokens=3000):\n",
    "    relevant_docs = vector_store.similarity_search(prompt, k=top_k)\n",
    "    context = \"\\n\\n\".join([doc.page_content[:max_tokens] for doc in relevant_docs])\n",
    "    full_prompt = f\"Using the following retrieved information, answer the question: {prompt}\\n\\n{context}\"\n",
    "\n",
    "    return call_gpt(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ddb51e-9e63-495c-ab55-eec4b46452a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information provided focuses primarily on the ongoing feud between two prominent hip-hop artists, Kendrick Lamar and Drake, rather than family matters in a traditional sense. However, both artists do have notable familial connections that are mentioned in their profiles.\n",
      "\n",
      "### Kendrick Lamar:\n",
      "- **Family**: Kendrick Lamar Duckworth, born June 17, 1987, in Compton, California, has familial ties to the music industry through his cousin, Baby Keem, who is also a rapper. Additionally, he is related to former NBA player Nick Young.\n",
      "- **Personal Life**: Kendrick is engaged to Whitney Alford, with whom he has been in a long-term relationship since their high school years. They have two children together.\n",
      "\n",
      "### Drake:\n",
      "- **Family**: Aubrey Drake Graham, born October 24, 1986, in Toronto, Ontario, has notable family relationships, including his uncle Larry Graham, who is a musician, and Teenie Hodges, another uncle with musical connections.\n",
      "- **Personal Life**: Drake has one child, Adonis, with artist Sophie Brussaux. He often discusses the impact of fatherhood on his life and music.\n",
      "\n",
      "### Overview of Their Feud:\n",
      "The feud between Kendrick Lamar and Drake has escalated recently, with both artists releasing diss tracks aimed at each other. Kendrick's recent work appears to directly challenge Drake's status and achievements in the music industry, reigniting their rivalry which has existed for several years. This public conflict has implications for their legacies and the hip-hop genre, showcasing a shift in how artists engage in rivalry.\n",
      "\n",
      "In summary, while the retrieved information highlights the professional rivalry and musical achievements of Kendrick Lamar and Drake, it also touches on their family backgrounds, illustrating how personal lives can intersect with their public personas in the music industry.\n"
     ]
    }
   ],
   "source": [
    "response = query_rag_with_embedding(\"Tell me about family matters\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdd45a-8a22-486c-9113-ff342ea99a17",
   "metadata": {},
   "source": [
    "### Basic RAG (Retrieval-Augmented Generation) - Summarization\n",
    "\n",
    "This section demonstrates **summarizing document content** using **GPT-4o Mini**.\n",
    "\n",
    "- **Context-Based Summarization**: Uses `summarize_rag()` to extract key insights from documents.  \n",
    "- **Efficient Information Extraction**: The model condenses long-form content into a concise response.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1296c1d0-fb92-4028-bae8-597919a56c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag_with_embedding(prompt, top_k=3, max_doc_length=1000):\n",
    "    relevant_docs = vector_store.similarity_search(prompt, k=top_k)    \n",
    "    truncated_docs = [doc.page_content[:max_doc_length] for doc in relevant_docs]\n",
    "    context = \"\\n\\n\".join(truncated_docs)\n",
    "    \n",
    "    full_prompt = f\"Using the following retrieved information, answer the question: {prompt}\\n\\n{context}\"\n",
    "    \n",
    "    response = call_gpt(full_prompt)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a0dea64-58c1-404b-aec0-d22a05cd920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The information provided does not directly address \"family matters.\" Instead, it focuses on the ongoing beef between two prominent hip-hop artists, Kendrick Lamar and Drake, detailing their recent diss exchanges and backgrounds. \n",
      "\n",
      "However, if you are interested in family matters related to either artist, here's a brief overview based on the retrieved information:\n",
      "\n",
      "- **Drake (Aubrey Drake Graham)** has one child and is related to notable musicians, including his uncles Larry Graham and Teenie Hodges.\n",
      "- **Kendrick Lamar (Kendrick Lamar Duckworth)** has been engaged to Whitney Alford since 2015 and has a focus on social commentary in his music.\n",
      "\n",
      "If you have a specific aspect of family matters you would like to explore further, please let me know!\n"
     ]
    }
   ],
   "source": [
    "response = query_rag_with_embedding(\"Tell me about family matters\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddc768-0213-4081-8b85-43a06fb0f046",
   "metadata": {},
   "source": [
    "### Advanced RAG (Routing & Sub-Questions)\n",
    "\n",
    "This section implements an **intelligent query router** that determines whether  \n",
    "to perform **vector search** or **summarization** based on the user's intent.\n",
    "\n",
    "- **Automatic Routing**: GPT-4o Mini decides if a query requires **search** (fact retrieval)  \n",
    "  or **summary** (document overview).  \n",
    "- **Dynamic Query Processing**: The model selects the appropriate approach and generates a response.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99ada167-331a-4a07-abac-2737a826bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_router_with_embedding(prompt, top_k=3, max_tokens=3000):\n",
    "    routing_prompt = (\n",
    "        \"Determine the best mode (search or summary) to process the given user query based on intent. \"\n",
    "        \"Return only 'search' if the query seeks specific facts, or 'summary' if the query requires summarization. \"\n",
    "        \"Respond with only 'search' or 'summary'.\\n\\n\"\n",
    "        f\"User Query: {prompt}\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=[{\"role\": \"user\", \"content\": routing_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    mode = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "    relevant_docs = vector_store.similarity_search(prompt, k=top_k)\n",
    "    context = \"\\n\\n\".join([doc.page_content[:max_tokens] for doc in relevant_docs]) \n",
    "\n",
    "    if mode == \"search\":\n",
    "        full_prompt = f\"Using the following retrieved information, find specific facts related to: {prompt}\\n\\n{context}\"\n",
    "    elif mode == \"summary\":\n",
    "        full_prompt = f\"Summarize the document with respect to: {prompt}\\n\\n{context}\"\n",
    "    else:\n",
    "        full_prompt = f\"{prompt}\\n\\n{context}\" \n",
    "\n",
    "    return call_gpt(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49ae2197-9bce-455b-9965-0a3e523ebfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song \"Meet the Grahams\" is significant as it emerges from a notable period of rivalry between two prominent figures in hip hop, Kendrick Lamar and Drake. This track is part of a broader narrative in which both artists have engaged in a series of diss tracks that have reshaped the dynamics of rap competition. The song highlights the intensity of their feud, particularly following Kendrick's declaration of \"war\" in his recent work, signifying a shift from friendly competition to more personal attacks.\n",
      "\n",
      "In the context of this evolving conflict, \"Meet the Grahams\" serves as a pivotal moment that amplifies the stakes in their rivalry. Kendrick‚Äôs verses are laden with direct references and veiled insults aimed at Drake, which marks a departure from previous interactions that were often more subdued and less confrontational. This escalation is significant for both artists‚Äô legacies, as it not only underscores their individual styles and lyrical prowess but also alters the landscape of hip-hop beefs, setting new expectations for future collaborations and diss tracks.\n",
      "\n",
      "Overall, the significance of \"Meet the Grahams\" lies in its encapsulation of the competitive spirit of hip hop, the evolution of Kendrick and Drake's relationship, and the impact that their feud may have on their careers and the genre at large.\n"
     ]
    }
   ],
   "source": [
    "response_search = query_router_with_embedding(\"Tell me about the song 'Meet the Grahams' - why is it significant\")\n",
    "print(response_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f3c6c5a-9928-469a-9753-14a74f037c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses the recent escalation of the feud between rappers Kendrick Lamar and Drake, highlighting its cultural significance within the hip-hop community. The rivalry has intensified, with both artists releasing diss tracks targeting each other in quick succession, marking a shift in how rap conflicts are engaged. Kendrick Lamar's latest verses have been particularly aggressive, signaling a clear declaration of animosity towards Drake. This ongoing conflict is not only reshaping their individual legacies but also altering the landscape of hip-hop, emphasizing the competitive nature of the genre. The document underscores that this beef has significant implications for the future dynamics of rap music, reflecting broader themes of rivalry and artistic expression in contemporary culture.\n"
     ]
    }
   ],
   "source": [
    "response_summary = query_router_with_embedding(\"Summarize the significance of 'Meet the Grahams'\")\n",
    "print(response_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2e239-b445-42a9-8876-4fe1ed584653",
   "metadata": {},
   "source": [
    "### Break Complex Questions into Sub-Questions\n",
    "\n",
    "This section implements a **Sub-Question Query Engine** that determines  \n",
    "whether a query is related to **Drake or Kendrick Lamar** and retrieves  \n",
    "relevant information accordingly.\n",
    "\n",
    "- **Automatic Subject Classification**: GPT-4o Mini classifies the query as  \n",
    "  related to **Drake** or **Kendrick** before fetching data.  \n",
    "- **Targeted Query Execution**: Uses `docs_drake` if the query is about Drake  \n",
    "  and `docs_kendrick` if it's about Kendrick.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "156779d1-bb0e-4cdb-84cb-e6680b88e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_subject(prompt):\n",
    "    classification_prompt = (\n",
    "        \"Determine whether the following question is about 'Drake' or 'Kendrick Lamar'. \"\n",
    "        \"Return only 'drake' or 'kendrick'.\\n\\n\"\n",
    "        f\"User Question: {prompt}\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d18ff945-c83e-4a50-af3f-3117ebba075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_question_query_engine_with_embedding(prompt, top_k=3, max_tokens=3000):\n",
    "    subject = determine_subject(prompt)\n",
    "    \n",
    "    if subject == \"drake\":\n",
    "        relevant_docs = vector_store.similarity_search(prompt, k=top_k)\n",
    "    else:  \n",
    "        relevant_docs = vector_store.similarity_search(prompt, k=top_k)\n",
    "\n",
    "    context = \"\\n\\n\".join([doc.page_content[:max_tokens] for doc in relevant_docs])\n",
    "\n",
    "    full_prompt = f\"Using the following retrieved information, answer the question: {prompt}\\n\\n{context}\"\n",
    "\n",
    "    return call_gpt(full_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a80304a-4845-4b8f-9e9b-3fe0b3b41a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drake has released the following albums in his career:\n",
      "\n",
      "1. **Thank Me Later** (2010)\n",
      "2. **Take Care** (2011)\n",
      "3. **Nothing Was the Same** (2013)\n",
      "4. **Views** (2016)\n",
      "5. **Scorpion** (2018)\n",
      "6. **Certified Lover Boy** (2021)\n",
      "7. **Honestly, Nevermind** (2022)\n",
      "8. **Her Loss** (2022, collaborative album with 21 Savage)\n",
      "9. **For All the Dogs** (2023)\n",
      "\n",
      "These albums have collectively contributed to Drake's status as a significant figure in contemporary music, achieving commercial success and critical acclaim.\n"
     ]
    }
   ],
   "source": [
    "response = sub_question_query_engine_with_embedding(\"Which albums did Drake release in his career?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a460e2f3-b9e0-41a9-a9cb-0d6843c2769a",
   "metadata": {},
   "source": [
    "### Text-to-SQL with GPT-4o Mini\n",
    "\n",
    "This section demonstrates **converting natural language queries into SQL**  \n",
    "to retrieve data from an SQLite database.\n",
    "\n",
    "- **Database Setup**:  \n",
    "  - Downloads and extracts the **Chinook SQLite database**, which contains  \n",
    "    music-related tables like `albums`, `artists`, and `tracks`.  \n",
    "  - Initializes a connection to `chinook.db` using SQLAlchemy.  \n",
    "\n",
    "- **SQL Query Generation**:  \n",
    "  - Uses GPT-4o Mini to **convert natural language questions into SQL queries**.  \n",
    "  - Restricts queries to the tables: `albums`, `artists`, and `tracks`.  \n",
    "\n",
    "- **Query Execution**:  \n",
    "  - Runs the generated SQL queries on the database and retrieves the results.  \n",
    "\n",
    "This setup allows **seamless querying of structured data** using natural language. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a25cda07-6675-4de5-a5a1-0d86185fd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filepath):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22635c4f-23a7-484e-b5d5-eedab846fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(\"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\", \"data/chinook.zip\")\n",
    "with zipfile.ZipFile(\"data/chinook.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13ff2e88-96c7-4072-8ba1-27d08925be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///data/chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d85ec73-23c8-4d8c-a0b3-1937f864afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_schema = {\n",
    "    \"albums\": \"AlbumId, Title, ArtistId\",\n",
    "    \"artists\": \"ArtistId, Name\",\n",
    "    \"tracks\": \"TrackId, Name, AlbumId, Composer, MediaTypeId, GenreId, Milliseconds, Bytes, UnitPrice\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20ac5307-9124-40db-b873-fcaea7017341",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_docs = [\n",
    "    Document(page_content=f\"Table: {table}\\nColumns: {columns}\", metadata={\"table\": table})\n",
    "    for table, columns in tables_schema.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75a199bb-8764-40a7-bf58-d5eddf586882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90376454-bfe2-46b3-8bc8-37bc41d98157',\n",
       " '221452eb-4a41-4857-8cde-59530dd85228',\n",
       " 'cefa6c06-b47b-44d1-a0ec-07d1bed41bb0']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(schema_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e308c803-fa2e-425b-a892-c4d25afc68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_schema(prompt, top_k=2):\n",
    "    relevant_schema = vector_store.similarity_search(prompt, k=top_k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in relevant_schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "872e0f8b-b066-4636-b479-db00fa384765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query_with_embedding(natural_language_query):\n",
    "    relevant_schema = retrieve_relevant_schema(natural_language_query)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Convert the following natural language question into a SQL query for a SQLite database.\n",
    "    Use only the relevant schema details provided below:\n",
    "\n",
    "    {relevant_schema}\n",
    "\n",
    "    **Now generate a SQL query for the following request:**\n",
    "    \n",
    "    \"{natural_language_query}\"\n",
    "    \n",
    "    **Return only the SQL query, without any explanation.**\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    sql_query = response.choices[0].message.content.strip()\n",
    "\n",
    "    if \"```sql\" in sql_query:\n",
    "        sql_query = sql_query.split(\"```sql\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d8d2760-8076-46bc-87dd-5dff3a790e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import text  \n",
    "\n",
    "def query_sql_database_with_embedding(natural_language_query):\n",
    "    sql_query = generate_sql_query_with_embedding(natural_language_query)\n",
    "    print(f\"Generated SQL Query: {sql_query}\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(sql_query))  \n",
    "        return [row for row in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9bc5afc-33b8-4029-b973-cee333e5ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT * FROM albums;\n",
      "Albums: [(1, 'For Those About To Rock We Salute You', 1), (2, 'Balls to the Wall', 2), (3, 'Restless and Wild', 2), (4, 'Let There Be Rock', 1), (5, 'Big Ones', 3), (6, 'Jagged Little Pill', 4), (7, 'Facelift', 5), (8, 'Warner 25 Anos', 6), (9, 'Plays Metallica By Four Cellos', 7), (10, 'Audioslave', 8), (11, 'Out Of Exile', 8), (12, 'BackBeat Soundtrack', 9), (13, 'The Best Of Billy Cobham', 10), (14, 'Alcohol Fueled Brewtality Live! [Disc 1]', 11), (15, 'Alcohol Fueled Brewtality Live! [Disc 2]', 11), (16, 'Black Sabbath', 12), (17, 'Black Sabbath Vol. 4 (Remaster)', 12), (18, 'Body Count', 13), (19, 'Chemical Wedding', 14), (20, 'The Best Of Buddy Guy - The Millenium Collection', 15), (21, 'Prenda Minha', 16), (22, 'Sozinho Remix Ao Vivo', 16), (23, 'Minha Historia', 17), (24, 'Afrociberdelia', 18), (25, 'Da Lama Ao Caos', 18), (26, 'Ac√∫stico MTV [Live]', 19), (27, 'Cidade Negra - Hits', 19), (28, 'Na Pista', 20), (29, 'Ax√© Bahia 2001', 21), (30, 'BBC Sessions [Disc 1] [Live]', 22), (31, 'Bongo Fury', 23), (32, 'Carnaval 2001', 21), (33, 'Chill: Brazil (Disc 1)', 24), (34, 'Chill: Brazil (Disc 2)', 6), (35, 'Garage Inc. (Disc 1)', 50), (36, 'Greatest Hits II', 51), (37, 'Greatest Kiss', 52), (38, 'Heart of the Night', 53), (39, 'International Superhits', 54), (40, 'Into The Light', 55), (41, 'Meus Momentos', 56), (42, 'Minha Hist√≥ria', 57), (43, 'MK III The Final Concerts [Disc 1]', 58), (44, 'Physical Graffiti [Disc 1]', 22), (45, 'Sambas De Enredo 2001', 21), (46, 'Supernatural', 59), (47, 'The Best of Ed Motta', 37), (48, 'The Essential Miles Davis [Disc 1]', 68), (49, 'The Essential Miles Davis [Disc 2]', 68), (50, 'The Final Concerts (Disc 2)', 58), (51, \"Up An' Atom\", 69), (52, 'Vin√≠cius De Moraes - Sem Limite', 70), (53, 'Vozes do MPB', 21), (54, 'Chronicle, Vol. 1', 76), (55, 'Chronicle, Vol. 2', 76), (56, 'C√°ssia Eller - Cole√ß√£o Sem Limite [Disc 2]', 77), (57, 'C√°ssia Eller - Sem Limite [Disc 1]', 77), (58, 'Come Taste The Band', 58), (59, 'Deep Purple In Rock', 58), (60, 'Fireball', 58), (61, \"Knocking at Your Back Door: The Best Of Deep Purple in the 80's\", 58), (62, 'Machine Head', 58), (63, 'Purpendicular', 58), (64, 'Slaves And Masters', 58), (65, 'Stormbringer', 58), (66, 'The Battle Rages On', 58), (67, \"Vault: Def Leppard's Greatest Hits\", 78), (68, 'Outbreak', 79), (69, 'Djavan Ao Vivo - Vol. 02', 80), (70, 'Djavan Ao Vivo - Vol. 1', 80), (71, 'Elis Regina-Minha Hist√≥ria', 41), (72, 'The Cream Of Clapton', 81), (73, 'Unplugged', 81), (74, 'Album Of The Year', 82), (75, 'Angel Dust', 82), (76, 'King For A Day Fool For A Lifetime', 82), (77, 'The Real Thing', 82), (78, 'Deixa Entrar', 83), (79, 'In Your Honor [Disc 1]', 84), (80, 'In Your Honor [Disc 2]', 84), (81, 'One By One', 84), (82, 'The Colour And The Shape', 84), (83, 'My Way: The Best Of Frank Sinatra [Disc 1]', 85), (84, 'Roda De Funk', 86), (85, 'As Can√ß√µes de Eu Tu Eles', 27), (86, 'Quanta Gente Veio Ver (Live)', 27), (87, 'Quanta Gente Veio ver--B√¥nus De Carnaval', 27), (88, 'Faceless', 87), (89, 'American Idiot', 54), (90, 'Appetite for Destruction', 88), (91, 'Use Your Illusion I', 88), (92, 'Use Your Illusion II', 88), (93, 'Blue Moods', 89), (94, 'A Matter of Life and Death', 90), (95, 'A Real Dead One', 90), (96, 'A Real Live One', 90), (97, 'Brave New World', 90), (98, 'Dance Of Death', 90), (99, 'Fear Of The Dark', 90), (100, 'Iron Maiden', 90), (101, 'Killers', 90), (102, 'Live After Death', 90), (103, 'Live At Donington 1992 (Disc 1)', 90), (104, 'Live At Donington 1992 (Disc 2)', 90), (105, 'No Prayer For The Dying', 90), (106, 'Piece Of Mind', 90), (107, 'Powerslave', 90), (108, 'Rock In Rio [CD1]', 90), (109, 'Rock In Rio [CD2]', 90), (110, 'Seventh Son of a Seventh Son', 90), (111, 'Somewhere in Time', 90), (112, 'The Number of The Beast', 90), (113, 'The X Factor', 90), (114, 'Virtual XI', 90), (115, 'Sex Machine', 91), (116, 'Emergency On Planet Earth', 92), (117, 'Synkronized', 92), (118, 'The Return Of The Space Cowboy', 92), (119, 'Get Born', 93), (120, 'Are You Experienced?', 94), (121, 'Surfing with the Alien (Remastered)', 95), (122, 'Jorge Ben Jor 25 Anos', 46), (123, 'Jota Quest-1995', 96), (124, 'Cafezinho', 97), (125, 'Living After Midnight', 98), (126, 'Unplugged [Live]', 52), (127, 'BBC Sessions [Disc 2] [Live]', 22), (128, 'Coda', 22), (129, 'Houses Of The Holy', 22), (130, 'In Through The Out Door', 22), (131, 'IV', 22), (132, 'Led Zeppelin I', 22), (133, 'Led Zeppelin II', 22), (134, 'Led Zeppelin III', 22), (135, 'Physical Graffiti [Disc 2]', 22), (136, 'Presence', 22), (137, 'The Song Remains The Same (Disc 1)', 22), (138, 'The Song Remains The Same (Disc 2)', 22), (139, 'A TempestadeTempestade Ou O Livro Dos Dias', 99), (140, 'Mais Do Mesmo', 99), (141, 'Greatest Hits', 100), (142, 'Lulu Santos - RCA 100 Anos De M√∫sica - √Ålbum 01', 101), (143, 'Lulu Santos - RCA 100 Anos De M√∫sica - √Ålbum 02', 101), (144, 'Misplaced Childhood', 102), (145, 'Barulhinho Bom', 103), (146, 'Seek And Shall Find: More Of The Best (1963-1981)', 104), (147, 'The Best Of Men At Work', 105), (148, 'Black Album', 50), (149, 'Garage Inc. (Disc 2)', 50), (150, \"Kill 'Em All\", 50), (151, 'Load', 50), (152, 'Master Of Puppets', 50), (153, 'ReLoad', 50), (154, 'Ride The Lightning', 50), (155, 'St. Anger', 50), (156, '...And Justice For All', 50), (157, 'Miles Ahead', 68), (158, 'Milton Nascimento Ao Vivo', 42), (159, 'Minas', 42), (160, 'Ace Of Spades', 106), (161, 'Demorou...', 108), (162, 'Motley Crue Greatest Hits', 109), (163, 'From The Muddy Banks Of The Wishkah [Live]', 110), (164, 'Nevermind', 110), (165, 'Compositores', 111), (166, 'Olodum', 112), (167, 'Ac√∫stico MTV', 113), (168, 'Arquivo II', 113), (169, 'Arquivo Os Paralamas Do Sucesso', 113), (170, 'Bark at the Moon (Remastered)', 114), (171, 'Blizzard of Ozz', 114), (172, 'Diary of a Madman (Remastered)', 114), (173, 'No More Tears (Remastered)', 114), (174, 'Tribute', 114), (175, 'Walking Into Clarksdale', 115), (176, 'Original Soundtracks 1', 116), (177, 'The Beast Live', 117), (178, 'Live On Two Legs [Live]', 118), (179, 'Pearl Jam', 118), (180, 'Riot Act', 118), (181, 'Ten', 118), (182, 'Vs.', 118), (183, 'Dark Side Of The Moon', 120), (184, 'Os C√£es Ladram Mas A Caravana N√£o P√°ra', 121), (185, 'Greatest Hits I', 51), (186, 'News Of The World', 51), (187, 'Out Of Time', 122), (188, 'Green', 124), (189, 'New Adventures In Hi-Fi', 124), (190, 'The Best Of R.E.M.: The IRS Years', 124), (191, 'Cesta B√°sica', 125), (192, 'Raul Seixas', 126), (193, 'Blood Sugar Sex Magik', 127), (194, 'By The Way', 127), (195, 'Californication', 127), (196, 'Retrospective I (1974-1980)', 128), (197, 'Santana - As Years Go By', 59), (198, 'Santana Live', 59), (199, 'Maquinarama', 130), (200, 'O Samba Pocon√©', 130), (201, 'Judas 0: B-Sides and Rarities', 131), (202, 'Rotten Apples: Greatest Hits', 131), (203, 'A-Sides', 132), (204, 'Morning Dance', 53), (205, 'In Step', 133), (206, 'Core', 134), (207, 'Mezmerize', 135), (208, '[1997] Black Light Syndrome', 136), (209, 'Live [Disc 1]', 137), (210, 'Live [Disc 2]', 137), (211, 'The Singles', 138), (212, 'Beyond Good And Evil', 139), (213, 'Pure Cult: The Best Of The Cult (For Rockers, Ravers, Lovers & Sinners) [UK]', 139), (214, 'The Doors', 140), (215, 'The Police Greatest Hits', 141), (216, 'Hot Rocks, 1964-1971 (Disc 1)', 142), (217, 'No Security', 142), (218, 'Voodoo Lounge', 142), (219, 'Tangents', 143), (220, 'Transmission', 143), (221, 'My Generation - The Very Best Of The Who', 144), (222, 'Serie Sem Limite (Disc 1)', 145), (223, 'Serie Sem Limite (Disc 2)', 145), (224, 'Ac√∫stico', 146), (225, 'Volume Dois', 146), (226, 'Battlestar Galactica: The Story So Far', 147), (227, 'Battlestar Galactica, Season 3', 147), (228, 'Heroes, Season 1', 148), (229, 'Lost, Season 3', 149), (230, 'Lost, Season 1', 149), (231, 'Lost, Season 2', 149), (232, 'Achtung Baby', 150), (233, \"All That You Can't Leave Behind\", 150), (234, 'B-Sides 1980-1990', 150), (235, 'How To Dismantle An Atomic Bomb', 150), (236, 'Pop', 150), (237, 'Rattle And Hum', 150), (238, 'The Best Of 1980-1990', 150), (239, 'War', 150), (240, 'Zooropa', 150), (241, 'UB40 The Best Of - Volume Two [UK]', 151), (242, 'Diver Down', 152), (243, 'The Best Of Van Halen, Vol. I', 152), (244, 'Van Halen', 152), (245, 'Van Halen III', 152), (246, 'Contraband', 153), (247, 'Vinicius De Moraes', 72), (248, 'Ao Vivo [IMPORT]', 155), (249, 'The Office, Season 1', 156), (250, 'The Office, Season 2', 156), (251, 'The Office, Season 3', 156), (252, 'Un-Led-Ed', 157), (253, 'Battlestar Galactica (Classic), Season 1', 158), (254, 'Aquaman', 159), (255, 'Instant Karma: The Amnesty International Campaign to Save Darfur', 150), (256, 'Speak of the Devil', 114), (257, '20th Century Masters - The Millennium Collection: The Best of Scorpions', 179), (258, 'House of Pain', 180), (259, 'Radio Brasil (O Som da Jovem Vanguarda) - Seleccao de Henrique Amaro', 36), (260, 'Cake: B-Sides and Rarities', 196), (261, 'LOST, Season 4', 149), (262, 'Quiet Songs', 197), (263, 'Muso Ko', 198), (264, 'Realize', 199), (265, 'Every Kind of Light', 200), (266, 'Duos II', 201), (267, 'Worlds', 202), (268, 'The Best of Beethoven', 203), (269, 'Temple of the Dog', 204), (270, 'Carry On', 205), (271, 'Revelations', 8), (272, 'Adorate Deum: Gregorian Chant from the Proper of the Mass', 206), (273, 'Allegri: Miserere', 207), (274, 'Pachelbel: Canon & Gigue', 208), (275, 'Vivaldi: The Four Seasons', 209), (276, 'Bach: Violin Concertos', 210), (277, 'Bach: Goldberg Variations', 211), (278, 'Bach: The Cello Suites', 212), (279, 'Handel: The Messiah (Highlights)', 213), (280, 'The World of Classical Favourites', 214), (281, 'Sir Neville Marriner: A Celebration', 215), (282, 'Mozart: Wind Concertos', 216), (283, 'Haydn: Symphonies 99 - 104', 217), (284, 'Beethoven: Symhonies Nos. 5 & 6', 218), (285, 'A Soprano Inspired', 219), (286, 'Great Opera Choruses', 220), (287, 'Wagner: Favourite Overtures', 221), (288, 'Faur√©: Requiem, Ravel: Pavane & Others', 222), (289, 'Tchaikovsky: The Nutcracker', 223), (290, 'The Last Night of the Proms', 224), (291, 'Puccini: Madama Butterfly - Highlights', 225), (292, 'Holst: The Planets, Op. 32 & Vaughan Williams: Fantasies', 226), (293, \"Pavarotti's Opera Made Easy\", 227), (294, \"Great Performances - Barber's Adagio and Other Romantic Favorites for Strings\", 228), (295, 'Carmina Burana', 229), (296, 'A Copland Celebration, Vol. I', 230), (297, 'Bach: Toccata & Fugue in D Minor', 231), (298, 'Prokofiev: Symphony No.1', 232), (299, 'Scheherazade', 233), (300, 'Bach: The Brandenburg Concertos', 234), (301, 'Chopin: Piano Concertos Nos. 1 & 2', 235), (302, 'Mascagni: Cavalleria Rusticana', 236), (303, 'Sibelius: Finlandia', 237), (304, 'Beethoven Piano Sonatas: Moonlight & Pastorale', 238), (305, 'Great Recordings of the Century - Mahler: Das Lied von der Erde', 240), (306, 'Elgar: Cello Concerto & Vaughan Williams: Fantasias', 241), (307, 'Adams, John: The Chairman Dances', 242), (308, \"Tchaikovsky: 1812 Festival Overture, Op.49, Capriccio Italien & Beethoven: Wellington's Victory\", 243), (309, 'Palestrina: Missa Papae Marcelli & Allegri: Miserere', 244), (310, 'Prokofiev: Romeo & Juliet', 245), (311, 'Strauss: Waltzes', 226), (312, 'Berlioz: Symphonie Fantastique', 245), (313, 'Bizet: Carmen Highlights', 246), (314, 'English Renaissance', 247), (315, 'Handel: Music for the Royal Fireworks (Original Version 1749)', 208), (316, 'Grieg: Peer Gynt Suites & Sibelius: Pell√©as et M√©lisande', 248), (317, 'Mozart Gala: Famous Arias', 249), (318, 'SCRIABIN: Vers la flamme', 250), (319, 'Armada: Music from the Courts of England and Spain', 251), (320, 'Mozart: Symphonies Nos. 40 & 41', 248), (321, 'Back to Black', 252), (322, 'Frank', 252), (323, 'Carried to Dust (Bonus Track Version)', 253), (324, \"Beethoven: Symphony No. 6 'Pastoral' Etc.\", 254), (325, 'Bartok: Violin & Viola Concertos', 255), (326, \"Mendelssohn: A Midsummer Night's Dream\", 256), (327, 'Bach: Orchestral Suites Nos. 1 - 4', 257), (328, 'Charpentier: Divertissements, Airs & Concerts', 258), (329, 'South American Getaway', 259), (330, 'G√≥recki: Symphony No. 3', 260), (331, 'Purcell: The Fairy Queen', 261), (332, 'The Ultimate Relexation Album', 262), (333, 'Purcell: Music for the Queen Mary', 263), (334, 'Weill: The Seven Deadly Sins', 264), (335, 'J.S. Bach: Chaconne, Suite in E Minor, Partita in E Major & Prelude, Fugue and Allegro', 265), (336, 'Prokofiev: Symphony No.5 & Stravinksy: Le Sacre Du Printemps', 248), (337, 'Szymanowski: Piano Works, Vol. 1', 266), (338, 'Nielsen: The Six Symphonies', 267), (339, \"Great Recordings of the Century: Paganini's 24 Caprices\", 268), (340, \"Liszt - 12 √âtudes D'Execution Transcendante\", 269), (341, 'Great Recordings of the Century - Shubert: Schwanengesang, 4 Lieder', 270), (342, 'Locatelli: Concertos for Violin, Strings and Continuo, Vol. 3', 271), (343, 'Respighi:Pines of Rome', 226), (344, \"Schubert: The Late String Quartets & String Quintet (3 CD's)\", 272), (345, \"Monteverdi: L'Orfeo\", 273), (346, 'Mozart: Chamber Music', 274), (347, 'Koyaanisqatsi (Soundtrack from the Motion Picture)', 275)]\n"
     ]
    }
   ],
   "source": [
    "response_albums = query_sql_database_with_embedding(\"What are some albums?\")\n",
    "print(\"Albums:\", response_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "082ab5a6-a4ab-40bb-914f-cbe8cc7d457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT * FROM artists LIMIT 5;\n",
      "Artists: [(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains')]\n"
     ]
    }
   ],
   "source": [
    "response_artists = query_sql_database_with_embedding(\"What are some artists? Limit it to 5.\")\n",
    "print(\"Artists:\", response_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df72f942-cdc8-477e-b1a2-70a70b757270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: SELECT Name FROM tracks WHERE Composer = 'AC/DC' LIMIT 3;\n",
      "AC/DC Tracks: [('Go Down',), ('Dog Eat Dog',), ('Let There Be Rock',)]\n"
     ]
    }
   ],
   "source": [
    "response_tracks = query_sql_database_with_embedding(\"What are some tracks from the artist AC/DC? Limit it to 3\")\n",
    "print(\"AC/DC Tracks:\", response_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6406730-5224-4475-b804-3f76553fa9f2",
   "metadata": {},
   "source": [
    "### Structured Data Extraction using GPT-4o Mini\n",
    "\n",
    "This section demonstrates **extracting structured data** from natural language  \n",
    "using **GPT-4o Mini** and returning it in **JSON format**.\n",
    "\n",
    "- **Data Extraction Process**:  \n",
    "  - The model generates structured data for a **restaurant** in a given city.  \n",
    "  - The output must be a **valid JSON object** containing:  \n",
    "    - `name`: The restaurant's name.  \n",
    "    - `city`: The specified city.  \n",
    "    - `cuisine`: The type of cuisine served.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90f8a676-e2f3-47c3-b141-e1efe102b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Restaurant(BaseModel):\n",
    "    \"\"\"A restaurant with name, city, and cuisine.\"\"\"\n",
    "    name: str\n",
    "    city: str\n",
    "    cuisine: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00491cf5-47d5-4314-a53b-5a080e0c8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_data = [\n",
    "    {\"name\": \"Joe's Seafood\", \"city\": \"Miami\", \"cuisine\": \"Seafood\"},\n",
    "    {\"name\": \"Pasta Paradise\", \"city\": \"New York\", \"cuisine\": \"Italian\"},\n",
    "    {\"name\": \"Sushi Haven\", \"city\": \"San Francisco\", \"cuisine\": \"Japanese\"},\n",
    "    {\"name\": \"BBQ King\", \"city\": \"Austin\", \"cuisine\": \"BBQ\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16c7ce34-56a4-483c-904a-6d349bc15fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b6cd8d6a-3b59-4609-ad1d-8cdf2a571c1d',\n",
       " '49377792-710e-4632-81a7-3f734748c6bb',\n",
       " '07d2e460-0d1e-43d4-ab30-80033a763d58',\n",
       " 'f67f33a3-fd24-4de6-88fe-3a8ac6026598']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_docs = [\n",
    "    Document(page_content=f\"Restaurant: {r['name']}, City: {r['city']}, Cuisine: {r['cuisine']}\", metadata={\"city\": r[\"city\"]})\n",
    "    for r in restaurant_data\n",
    "]\n",
    "\n",
    "vector_store.add_documents(restaurant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a7f3fc8-a50a-4c10-a95b-53d5a8ca6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_restaurants_by_city(city_name, top_k=3):\n",
    "    relevant_docs = vector_store.similarity_search(city_name, k=top_k)\n",
    "    return relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c07bfdde-ac7a-4a42-a8a6-a6fde91c216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_data_with_embedding(city_name):\n",
    "    relevant_restaurants = retrieve_restaurants_by_city(city_name)\n",
    "\n",
    "    if not relevant_restaurants:\n",
    "        prompt = f\"Generate a restaurant in a given city: {city_name}. Return only a valid JSON object with keys: name, city, cuisine, without markdown formatting.\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=llm_config[\"model\"],\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        structured_data = response.choices[0].message.content.strip()\n",
    "\n",
    "        if \"```json\" in structured_data:\n",
    "            structured_data = structured_data.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        try:\n",
    "            json_data = json.loads(structured_data)\n",
    "            return Restaurant.model_validate(json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON Decode Error:\", e)\n",
    "            print(\"Raw Response:\", structured_data)\n",
    "            return None\n",
    "\n",
    "    restaurant_list = []\n",
    "    for doc in relevant_restaurants:\n",
    "        parts = doc.page_content.split(\", \")\n",
    "        restaurant_dict = {\n",
    "            \"name\": parts[0].split(\": \")[1],\n",
    "            \"city\": parts[1].split(\": \")[1],\n",
    "            \"cuisine\": parts[2].split(\": \")[1],\n",
    "        }\n",
    "        restaurant_list.append(Restaurant(**restaurant_dict))\n",
    "\n",
    "    return restaurant_list[0] if restaurant_list else None  # Return the first matching restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c68934f-34a2-4349-bb02-d4b9371e20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name=\"Joe's Seafood\" city='Miami' cuisine='Seafood'\n"
     ]
    }
   ],
   "source": [
    "restaurant_obj = extract_structured_data_with_embedding(\"Miami\")\n",
    "print(restaurant_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76bea9f-a8ef-4587-b484-7bd5222ed52f",
   "metadata": {},
   "source": [
    "### Adding Chat History to RAG (Chat Engine)\n",
    "\n",
    "This section implements a **stateful chatbot** that integrates **chat history**  \n",
    "with **Retrieval-Augmented Generation (RAG)** to provide more context-aware responses.\n",
    "\n",
    "- **Chat Memory Management**:  \n",
    "  - Stores past interactions in `ChatMemory` to maintain conversation flow.  \n",
    "  - Limits stored messages to prevent exceeding token constraints.  \n",
    "\n",
    "- **Contextual Retrieval**:  \n",
    "  - Combines **user input, past chat history, and relevant document context**  \n",
    "    (e.g., about Kendrick & Drake) to generate informed responses.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc2f06b1-2266-4269-ad38-39f772db01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "class ChatMemoryWithEmbeddings:\n",
    "    def __init__(self, token_limit=10000): \n",
    "        self.token_limit = token_limit\n",
    "        self.messages = []\n",
    "        self.vector_store = vector_store  \n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "        doc = Document(page_content=content[:1000], metadata={\"role\": role}) \n",
    "        self.vector_store.add_documents([doc])\n",
    "\n",
    "        if len(self.messages) > 20:  \n",
    "            self.messages.pop(0)\n",
    "\n",
    "    def retrieve_relevant_history(self, prompt, top_k=2):\n",
    "        relevant_docs = self.vector_store.similarity_search(prompt, k=top_k)\n",
    "        return \"\\n\\n\".join([doc.page_content[:500] for doc in relevant_docs])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09c2749d-fe97-407a-86af-3958e38b886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryWithEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64c88de2-f465-434d-abd2-a3dd851e6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_history_using_embeddings(prompt):\n",
    "    relevant_history = memory.retrieve_relevant_history(prompt, top_k=2)\n",
    "\n",
    "    relevant_docs = vector_store.similarity_search(prompt, k=2)\n",
    "    document_context = \"\\n\\n\".join([doc.page_content[:1000] for doc in relevant_docs])  # Limit document size\n",
    "\n",
    "    context_prompt = (\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk \"\n",
    "        \"about the Kendrick and Drake beef. Use the retrieved chat history and document context:\\n\\n\"\n",
    "        f\"Chat History (trimmed):\\n{relevant_history}\\n\\n\"\n",
    "        f\"Relevant Documents (trimmed):\\n{document_context}\\n\\n\"\n",
    "        \"Instruction: Use the previous chat history, or the context above, to interact and help the user.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": context_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    total_tokens = sum(len(msg[\"content\"].split()) for msg in messages)\n",
    "    if total_tokens > 10000:\n",
    "        print(f\"Warning: Trimming messages to fit within token limit.\")\n",
    "        messages = messages[-5:]  \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    response_content = response.choices[0].message.content.strip()\n",
    "    memory.add_message(\"assistant\", response_content) \n",
    "\n",
    "    return response_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88d440a4-d8d2-4fb3-a2b8-f653d792437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the recent escalation of the beef between Kendrick Lamar and Drake, Drake released a three-part response that included a music video. While the specific titles of the songs weren't mentioned in the chat history, this kind of release typically involves sharp lyrics aimed at Kendrick, showcasing Drake's lyrical prowess and addressing the ongoing conflict.\n",
      "\n",
      "Drake's strategy often includes clever wordplay and personal jabs, which can resonate well with his audience. Kendrick, known for his aggressive and introspective style, usually responds with equal intensity. If you‚Äôre looking for more detailed information on the specific titles and content of the songs, I can help summarize their themes or lyrical content based on their previous discographies!\n"
     ]
    }
   ],
   "source": [
    "response = chat_with_history_using_embeddings(\"Tell me about the songs Drake released in the beef.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49623a55-063e-451f-a0cf-d9fd9a8f39df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendrick Lamar is widely regarded as one of the greatest rappers of all time. He was born on June 17, 1987, in Compton, California, and began his music career under the stage name K.Dot while still in high school. He signed with Top Dawg Entertainment in 2005 and quickly gained recognition for his unique style, which combines personal storytelling with social and political commentary.\n",
      "\n",
      "Kendrick is known for his intricate lyricism and thought-provoking themes, often addressing issues like race, identity, and systemic inequality. His album \"DAMN.\" won the Pulitzer Prize for Music in 2018, making him the first non-classical or jazz musician to receive this honor.\n",
      "\n",
      "In the context of his ongoing beef with Drake, Kendrick's approach tends to be more aggressive and introspective, often using his lyrics to make sharp social critiques. If you want to know more about his discography or specific songs, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = chat_with_history_using_embeddings(\"What about Kendrick?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe41bf6-42a7-42c1-aacc-9669ecebe40d",
   "metadata": {},
   "source": [
    "## 7. Agents\n",
    "\n",
    "Here we build agents with gpt-4o-mini . We perform RAG over simple functions as well as the documents above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "beff8bb7-831a-458d-aa92-22078d7965ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df672c9b-bf67-47dd-a372-f5bf7cc57905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mathematical functions\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and return the result.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and return the result.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two integers and return the result.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two integers and return the result.\"\"\"\n",
    "    return a / b if b != 0 else \"Cannot divide by zero\"\n",
    "\n",
    "# Function map for the agent\n",
    "tools = {\n",
    "    \"multiply\": multiply,\n",
    "    \"add\": add,\n",
    "    \"subtract\": subtract,\n",
    "    \"divide\": divide\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df2725f7-361b-4795-9196-4d19c11cc3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_examples = [\n",
    "    {\"function\": \"multiply\", \"query\": \"What is 5 times 3?\", \"args\": [5, 3]},\n",
    "    {\"function\": \"add\", \"query\": \"What is 10 plus 4?\", \"args\": [10, 4]},\n",
    "    {\"function\": \"subtract\", \"query\": \"What is 20 minus 7?\", \"args\": [20, 7]},\n",
    "    {\"function\": \"divide\", \"query\": \"What is 15 divided by 5?\", \"args\": [15, 5]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a0dff64-68cb-42ca-9b3b-85559e0f428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4b78c853-6601-4f64-a7c4-a44d0d609e48',\n",
       " 'aee11b5a-11fc-43a2-94b6-522cb819e09c',\n",
       " '210ce946-259b-4e7a-add0-c69d6dcdeec9',\n",
       " 'a8f07c6c-fcde-4212-ba8c-2f7b11914ceb']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_docs = [\n",
    "    Document(page_content=f\"Query: {ex['query']}, Function: {ex['function']}, Args: {ex['args']}\")\n",
    "    for ex in function_examples\n",
    "]\n",
    "\n",
    "vector_store.add_documents(function_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6567f784-6441-4f25-9a40-4abebaf45c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc6298ce-c15d-4149-9b44-ba4d133ae14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_function_examples(prompt, top_k=2):\n",
    "    relevant_docs = vector_store.similarity_search(prompt, k=top_k)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a19d0ab-ed6c-404e-970f-cd1629959a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool(tool_name, *args):\n",
    "    if tool_name in tools:\n",
    "        return tools[tool_name](*args)\n",
    "    return \"Invalid tool request\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f380155-d053-476f-ab8b-dbbbee05098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_chat_with_embeddings(prompt):\n",
    "    relevant_examples = retrieve_relevant_function_examples(prompt)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a smart assistant capable of performing arithmetic operations. \"\n",
    "        \"You can use the following functions: multiply, add, subtract, divide. \"\n",
    "        \"Below are relevant past function calls for reference:\\n\\n\"\n",
    "        f\"{relevant_examples}\\n\\n\"\n",
    "        \"When given a math question, return the correct function and inputs in JSON format. \"\n",
    "        \"Ensure the JSON output follows this format:\\n\\n\"\n",
    "        \"{\\n  \\\"function\\\": \\\"function_name\\\",\\n  \\\"arguments\\\": [arg1, arg2]\\n}\\n\\n\"\n",
    "        \"Return only valid JSON with no extra text or formatting.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    response_content = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        if \"```json\" in response_content:\n",
    "            response_content = response_content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        tool_request = json.loads(response_content)\n",
    "        tool_name = tool_request.get(\"function\")\n",
    "        arguments = tool_request.get(\"arguments\", [])\n",
    "\n",
    "        result = execute_tool(tool_name, *arguments)\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse response:\", response_content)\n",
    "        return \"Error: Could not parse the response as JSON.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ca187e4-1af9-423f-a15c-1d9356fb3140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n"
     ]
    }
   ],
   "source": [
    "response = agent_chat_with_embeddings(\"What is (121 + 2) * 5?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063eb77-63ce-4b55-8c22-e84e5d40a162",
   "metadata": {},
   "source": [
    "### ReAct Agent with RAG QueryEngine Tools\n",
    "\n",
    "This section implements a **ReAct-style agent** that dynamically selects between  \n",
    "**Drake-related** and **Kendrick-related** document retrieval using **GPT-4o Mini**.\n",
    "\n",
    "- **ReAct Framework**:  \n",
    "  - Uses **reasoning + action** to **select the right tool** for querying.  \n",
    "  - Determines whether to call **`query_drake`** or **`query_kendrick`** based on the prompt.  \n",
    "\n",
    "- **Tool-Based Query Execution**:  \n",
    "  - **GPT-4o Mini** analyzes the query and responds in **JSON format** specifying the correct tool.  \n",
    "  - The tool is then **executed dynamically** to fetch relevant information.  \n",
    "\n",
    "This approach enables **intelligent document selection** and **enhanced retrieval accuracy**. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d623a6a-8bd3-4b7d-956e-4a016e769258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def query_rag_with_embedding(prompt, top_k=3, max_tokens=3000):\n",
    "    relevant_docs = vector_store.similarity_search(prompt, k=top_k)\n",
    "\n",
    "    context = \"\\n\\n\".join([doc.page_content[:max_tokens] for doc in relevant_docs])\n",
    "\n",
    "    full_prompt = f\"Using the following retrieved information, answer the question: {prompt}\\n\\n{context}\"\n",
    "\n",
    "    return call_gpt(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03ae1a00-5337-4d56-9eea-6945f1bf7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_subject_using_embeddings(prompt):\n",
    "    classification_prompt = (\n",
    "        \"Determine whether the following question is about 'Drake' or 'Kendrick Lamar'. \"\n",
    "        \"Return only 'drake' or 'kendrick'.\\n\\n\"\n",
    "        f\"User Query: {prompt}\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=[{\"role\": \"user\", \"content\": classification_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5f6e628-751d-44f3-8d8f-b136fe38ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_agent_with_embeddings(prompt):\n",
    "    subject = determine_subject_using_embeddings(prompt)\n",
    "\n",
    "    relevant_docs = vector_store.similarity_search(prompt, k=3)\n",
    "    document_context = \"\\n\\n\".join([doc.page_content[:1000] for doc in relevant_docs])  # Limit document size\n",
    "\n",
    "    system_prompt = (\n",
    "        f\"You are an AI assistant capable of retrieving and summarizing information about Drake and Kendrick Lamar. \"\n",
    "        f\"Use the retrieved document context below to generate your response:\\n\\n\"\n",
    "        f\"Relevant Documents (trimmed):\\n{document_context}\\n\\n\"\n",
    "        f\"Instruction: Answer the user's query using the provided context.\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_config[\"model\"],\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4165211d-8f7e-4af7-ad41-d5e57bc8e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendrick Lamar was born on June 17, 1987, in Compton, California. He began his music career under the stage name K.Dot while still in high school. Growing up in Compton, Kendrick was influenced by the environment around him, which shaped his music and lyrical themes. His work often reflects personal storytelling intertwined with social and political commentary, addressing issues like race, identity, and systemic inequality.\n",
      "\n",
      "Drake, on the other hand, was born on October 24, 1986, in Toronto, Canada. He grew up in a mixed-race household, with his father being African American and his mother being Jewish Canadian. Drake's early life was marked by his experiences in the entertainment industry, as he started acting in the Canadian teen drama series \"Degrassi: The Next Generation.\" His background in acting and music eventually led him to pursue a career in hip-hop, where he became known for his emotional and introspective style.\n",
      "\n",
      "While both artists have different backgrounds‚ÄîKendrick's rooted in the struggles of Compton and Drake's in the diverse culture of Toronto‚Äîthey both draw from their experiences to create impactful music that resonates with their audiences.\n"
     ]
    }
   ],
   "source": [
    "response = react_agent_with_embeddings(\"Tell me about how Kendrick and Drake grew up\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ceb220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_lab_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
